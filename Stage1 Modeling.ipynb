{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Stage 1\n",
    "\n",
    "In this stage, we are trying to predict whether the customer will buy in their current session or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "#features selection and class imbalance\n",
    "from sklearn.feature_selection import RFE, VarianceThreshold\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.kernel_approximation import PolynomialCountSketch\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "#machine learning models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "#model performance evaluation\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, roc_auc_score, roc_curve, confusion_matrix\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('final_session_level_train.csv')\n",
    "test = pd.read_csv('final_session_level_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Session ID</th>\n",
       "      <th>num_clicks_session</th>\n",
       "      <th>buy_flag</th>\n",
       "      <th>session_length</th>\n",
       "      <th>Avg_time_bet_clicks</th>\n",
       "      <th>Max_time_bet_clicks</th>\n",
       "      <th>unique_items</th>\n",
       "      <th>max_click_per_item</th>\n",
       "      <th>max_hour</th>\n",
       "      <th>max_day</th>\n",
       "      <th>max_month</th>\n",
       "      <th>Avg_item_price</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>perc_prod_offer</th>\n",
       "      <th>perc_prod_no_cat</th>\n",
       "      <th>perc_prod_pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>351.0</td>\n",
       "      <td>116.666667</td>\n",
       "      <td>180.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2669.000000</td>\n",
       "      <td>0.020006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>359.0</td>\n",
       "      <td>71.400000</td>\n",
       "      <td>118.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2382.333333</td>\n",
       "      <td>0.006365</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>745.0</td>\n",
       "      <td>372.000000</td>\n",
       "      <td>495.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4701.595023</td>\n",
       "      <td>0.026714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>1034.000000</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>20315.500000</td>\n",
       "      <td>0.006692</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>246.0</td>\n",
       "      <td>246.000000</td>\n",
       "      <td>246.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>6336.696891</td>\n",
       "      <td>0.025385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1206.662927</td>\n",
       "      <td>0.078417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>133.0</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>133.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2303.000000</td>\n",
       "      <td>0.120482</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>169.0</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1674.000000</td>\n",
       "      <td>0.023930</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>True</td>\n",
       "      <td>783.0</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>385.0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>990.447912</td>\n",
       "      <td>0.021625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>179.0</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>179.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1749.868852</td>\n",
       "      <td>0.022427</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Session ID  num_clicks_session  buy_flag  session_length  \\\n",
       "0           0           1                   4     False           351.0   \n",
       "1           1           2                   6     False           359.0   \n",
       "2           2           3                   3     False           745.0   \n",
       "3           3           4                   2     False          1034.0   \n",
       "4           4           6                   2     False           246.0   \n",
       "5           5           7                   2     False            12.0   \n",
       "6           6           8                   2     False           133.0   \n",
       "7           7           9                   3     False           169.0   \n",
       "8           8          11                  12      True           783.0   \n",
       "9           9          12                   2      True           179.0   \n",
       "\n",
       "   Avg_time_bet_clicks  Max_time_bet_clicks  unique_items  max_click_per_item  \\\n",
       "0           116.666667                180.0             4                   1   \n",
       "1            71.400000                118.0             5                   2   \n",
       "2           372.000000                495.0             3                   1   \n",
       "3          1034.000000               1034.0             2                   1   \n",
       "4           246.000000                246.0             2                   1   \n",
       "5            12.000000                 12.0             2                   1   \n",
       "6           133.000000                133.0             1                   2   \n",
       "7            84.000000                150.0             1                   3   \n",
       "8            71.000000                385.0             9                   3   \n",
       "9           179.000000                179.0             1                   2   \n",
       "\n",
       "   max_hour  max_day  max_month  Avg_item_price  Popularity  perc_prod_offer  \\\n",
       "0        10        0          4     2669.000000    0.020006              0.0   \n",
       "1        14        0          4     2382.333333    0.006365              0.0   \n",
       "2        13        2          4     4701.595023    0.026714              0.0   \n",
       "3        12        0          4    20315.500000    0.006692              0.0   \n",
       "4        17        6          4     6336.696891    0.025385              0.0   \n",
       "5         6        2          4     1206.662927    0.078417              0.0   \n",
       "6         8        6          4     2303.000000    0.120482              0.0   \n",
       "7        11        6          4     1674.000000    0.023930              0.0   \n",
       "8        10        3          4      990.447912    0.021625              0.0   \n",
       "9        10        2          4     1749.868852    0.022427              0.0   \n",
       "\n",
       "   perc_prod_no_cat  perc_prod_pop  \n",
       "0               1.0       0.500000  \n",
       "1               1.0       0.800000  \n",
       "2               1.0       0.000000  \n",
       "3               1.0       0.500000  \n",
       "4               1.0       0.000000  \n",
       "5               1.0       0.000000  \n",
       "6               1.0       0.000000  \n",
       "7               1.0       0.000000  \n",
       "8               1.0       0.333333  \n",
       "9               1.0       0.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When inspecting the dataset, we observed that we need to transform the buy_flag feature to numerical values before running our model. We also dropped columns that will not be needed later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing data\n",
    "buy = pd.get_dummies(train['buy_flag'], drop_first=True) \n",
    "train = pd.concat([train, buy], axis=1)\n",
    "train.columns = [*train.columns[:-1], 'Buy']\n",
    "\n",
    "buy = pd.get_dummies(test['buy_flag'], drop_first=True) \n",
    "test = pd.concat([test, buy], axis=1)\n",
    "test.columns = [*test.columns[:-1], 'Buy']\n",
    "\n",
    "rmv_col = ['buy_flag', 'Unnamed: 0', 'Session ID']\n",
    "train = train.drop(rmv_col, axis=1)\n",
    "test = test.drop(rmv_col, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As observed below, our data is highly imbalanced, with 95% of data classified as class 0 and 5% of data classified as class 1. We will need to address this when running our model, either by specifying in the parameters or performing different sampling techniques, such as over-sampling or under-sampling to balance the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d7f01f77c0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x = 'Buy', data=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will split the full dataset into training and testing set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(\"Buy\", axis=1)\n",
    "y_train = train[\"Buy\"]\n",
    "\n",
    "X_test = test.drop(\"Buy\", axis=1)\n",
    "y_test = test[\"Buy\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will compare the performances of 8 different models: Logistic Regression, XGBoost, Support Vector Machine (SVM), Neural Networks, CatBoost, Light GBM, and Stack Generalizer on the sample dataset. On the full dataset, we will implement Logistic Regression, XGBoost, CatBoost, and SVM. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will train the Logistic Regression model on the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lilyn199/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass n_features_to_select=20 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lilyn199/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "rfe = RFE(logreg, 20)\n",
    "rfe = rfe.fit(X_train, y_train.values.ravel())\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lilyn199/opt/anaconda3/lib/python3.8/site-packages/statsmodels/discrete/discrete_model.py:1747: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-X))\n",
      "/Users/lilyn199/opt/anaconda3/lib/python3.8/site-packages/statsmodels/discrete/discrete_model.py:1800: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(np.log(self.cdf(q*np.dot(X,params))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: inf\n",
      "         Iterations 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lilyn199/opt/anaconda3/lib/python3.8/site-packages/statsmodels/base/model.py:547: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  warn('Inverting hessian failed, no bse or cov_params '\n",
      "/Users/lilyn199/opt/anaconda3/lib/python3.8/site-packages/statsmodels/base/model.py:547: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  warn('Inverting hessian failed, no bse or cov_params '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Results: Logit\n",
      "=====================================================================\n",
      "Model:                  Logit              Pseudo R-squared:   inf   \n",
      "Dependent Variable:     Buy                AIC:                inf   \n",
      "Date:                   2021-06-09 17:38   BIC:                inf   \n",
      "No. Observations:       7710267            Log-Likelihood:     -inf  \n",
      "Df Model:               13                 LL-Null:            0.0000\n",
      "Df Residuals:           7710253            LLR p-value:        1.0000\n",
      "Converged:              1.0000             Scale:              1.0000\n",
      "No. Iterations:         8.0000                                       \n",
      "---------------------------------------------------------------------\n",
      "                     Coef.  Std.Err.     z     P>|z|   [0.025  0.975]\n",
      "---------------------------------------------------------------------\n",
      "num_clicks_session   0.0617   0.0014   43.0761 0.0000  0.0589  0.0645\n",
      "session_length       0.0001   0.0000   34.5262 0.0000  0.0001  0.0001\n",
      "Avg_time_bet_clicks  0.0001   0.0000    7.9507 0.0000  0.0000  0.0001\n",
      "Max_time_bet_clicks  0.0002   0.0000   23.9144 0.0000  0.0002  0.0002\n",
      "unique_items         0.0024   0.0016    1.4789 0.1392 -0.0008  0.0057\n",
      "max_click_per_item   0.2708   0.0024  111.8103 0.0000  0.2660  0.2755\n",
      "max_hour            -0.0217   0.0003  -69.1351 0.0000 -0.0223 -0.0211\n",
      "max_day              0.0372   0.0008   49.5423 0.0000  0.0357  0.0387\n",
      "max_month           -0.4864   0.0010 -483.7047 0.0000 -0.4884 -0.4845\n",
      "Avg_item_price      -0.0000   0.0000  -17.1287 0.0000 -0.0000 -0.0000\n",
      "Popularity          13.5708   0.0466  291.4130 0.0000 13.4796 13.6621\n",
      "perc_prod_offer     -0.6014   0.0055 -108.5867 0.0000 -0.6123 -0.5906\n",
      "perc_prod_no_cat    -1.6353   0.0042 -388.6373 0.0000 -1.6435 -1.6270\n",
      "perc_prod_pop       -1.5209   0.0102 -149.7589 0.0000 -1.5408 -1.5009\n",
      "=====================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logit_model = sm.Logit(y_train,X_train)\n",
    "result = logit_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As unique_items has a p-value greater than 0.05, which indicates that this feature is not significant, we will drop it from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(\"unique_items\", axis=1)\n",
    "X_test= X_test.drop(\"unique_items\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply SMOTE to handle class imbalance before training our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of oversampled data is  14563364\n",
      "Number of no default in oversampled data 7281682\n",
      "Number of default 7281682\n",
      "Proportion of no default data in oversampled data is  0.5\n",
      "Proportion of default data in oversampled data is  0.5\n"
     ]
    }
   ],
   "source": [
    "os = SMOTE(random_state = 42, n_jobs=-1)\n",
    "columns = X_train.columns\n",
    "\n",
    "os_data_X, os_data_y = os.fit_resample(X_train, y_train)\n",
    "os_data_X = pd.DataFrame(data = os_data_X,columns = columns)\n",
    "os_data_y = pd.DataFrame(data = os_data_y,columns = ['Buy'])\n",
    "\n",
    "print(\"length of oversampled data is \",len(os_data_X))\n",
    "print(\"Number of no default in oversampled data\",len(os_data_y[os_data_y['Buy'] == 0]))\n",
    "print(\"Number of default\",len(os_data_y[os_data_y['Buy'] == 1]))\n",
    "print(\"Proportion of no default data in oversampled data is \",len(os_data_y[os_data_y['Buy'] == 0])/len(os_data_X))\n",
    "print(\"Proportion of default data in oversampled data is \",len(os_data_y[os_data_y['Buy'] == 1])/len(os_data_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lilyn199/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/Users/lilyn199/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(os_data_X, os_data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate the ROC Curve to find the optimal threshold where our model will achieve highest performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd1zV9f7A8ddbECcgorhwL1zgHl3NkZkN02xr5WhZZmneyvay27JbmZZ5S/3dsszbVCst03KkKSounOFgqICDpSDj8/vjcyRCxKNyOHB4Px8PHp5zvut9Dvh9n88WYwxKKaXUuZRzdwBKKaVKNk0USimlCqWJQimlVKE0USillCqUJgqllFKF0kShlFKqUJoo1EURke0i0sfdcbibiMwQkWeL+ZpzRGRycV7TVURkuIj8dJHH6t9gMREdR1H6ich+oBaQDaQCi4GHjDGp7ozL04jISOAeY0xPN8cxB4gxxjzj5jheAJoZY+4ohmvNoQS857JKSxSeY5AxpirQHugAPOnmeC6YiHiXxWu7k37myhmaKDyMMeYwsASbMAAQke4i8ruInBCRzXmL6yJSXURmi0iciBwXkW/zbLtORCIcx/0uIqF5tu0Xkf4iUldETolI9TzbOohIooiUdzwfLSI7HOdfIiIN8+xrRGSsiOwB9hT0nkTkekc1wwkR+VVEWuWL40kRiXScf7aIVLyA9/CEiGwB0kTEW0QmicifIpLiOOcNjn1bATOAHiKSKiInHK/nVgOJSB8RiRGRiSISLyKHRGRUnusFishCEUkWkfUiMllEVp3rdykiPfP83qIdJZozAkTke0ecf4hI0zzHvevYP1lENohIrzzbXhCRL0XkUxFJBkaKSFcRWeO4ziERmSYiPnmOaSMiP4vIMRE5IiJPichA4CngVsfnsdmxr7+IfOw4T6zjPXo5to0UkdUi8raIHANecLy2yrFdHNviRSRJRLaISFsRuQ8YDjzuuNbCPL+//o7HXo64zvzuNohI/XN9tuoCGWP0p5T/APuB/o7HwcBW4F3H83rAUeAa7BeDKx3Pazq2fw98AQQA5YHejtc7AvFAN8ALGOG4ToUCrrkMuDdPPG8CMxyPhwB7gVaAN/AM8HuefQ3wM1AdqFTAe2sBpDniLg887jifT544tgH1HedYDUy+gPcQ4Ti2kuO1m4G6js/qVse16zi2jQRW5YtvTp7r9QGygJccsV4DnAQCHNvnOX4qA62B6Pzny3PeBkAKcLvjXIFA+zzXPAZ0dXymc4F5eY69w7G/NzAROAxUdGx7Ach0/F7KAZWATkB3x/6NgB3AeMf+vsAhx3kqOp53y3OuT/PF/S3wIVAFCALWAffn+fyygHGOa1XK+5kCVwEbgGqAYP9m6uT/nM/xd/8Y9u++pePYMCDQ3f83PeXH7QHoTxH8Eu1/mFTHjcUAvwDVHNueAD7Jt/8S7E2zDpBz5kaWb58PgJfzvbaLvxJJ3v+k9wDLHI/FcQO83PH8R+DuPOcoh715NnQ8N0C/Qt7bs8D8fMfHAn3yxDEmz/ZrgD8v4D2MPs9nGwEMdjzOvanl2Z57A8MmilOAd57t8dibsBf2Bt0yz7bJ+c+XZ9uTwDfn2DYH+Cjfe95ZyHs4DoQ5Hr8ArDjPex5/5trYRLXpHPu9QJ5EgW0nyyBPwnccvzzP53cw3zlyP1OgH7Db8XmVO9fnnO/v/szf4K4zvyf9KfofrXryHEOMMb7Ym1UIUMPxekPgZke1wglHlUlPbJKoDxwzxhwv4HwNgYn5jquP/bad35fYKpm6wOXYm//KPOd5N885jmGTSb08x0cX8r7qAgfOPDHG5Dj2P9fxB/LE6Mx7+Nu1ReSuPFVVJ4C2/PVZOuOoMSYrz/OTQFWgJvZbdN7rFfa+6wN/FrL9cAHXAMBR9bXDUX1zAvDn7+8h/3tuISKLROSwozrqX3n2P18ceTXEln4O5fn8PsSWLAq8dl7GmGXANGA6cEREZoqIn5PXvpA41QXSROFhjDG/Yb99TXG8FI0tUVTL81PFGPOaY1t1EalWwKmigVfyHVfZGPN5Adc8AfwE3AIMAz43jq95jvPcn+88lYwxv+c9RSFvKQ57AwJsPTb2phCbZ5+8ddENHMc4+x5yry227eQ/wEPYaotq2GotcSLO80nAVrsEnyPu/KKBpoVsL5CjPeIJ7O8iwPEekvjrPcDZ7+MDYCfQ3Bjjh217OLN/YXHkP080tkRRI8/n7WeMaVPIMX8/oTFTjTGdgDbYasfHnDnuPHGqS6SJwjO9A1wpIu2BT4FBInKVo8GvoqPRNdgYcwhbNfS+iASISHkRudxxjv8AY0Skm6ORsYqIXCsivue45mfAXcCNjsdnzACeFJE2kNvYefMFvJf5wLUicoXYxvGJ2JtR3kQzVkSCxTaoP4Vtc7mY91AFe0NKcMQ6CluiOOMIEJy3oddZxphs4GtsA25lEQnBfl7nMhfoLyK3iG1kD3T8Ps/HF5uQEgBvEXkOON+3cl8gGUh1xPVAnm2LgNoiMl5EKoiIr4h0c2w7AjQSkXKO93gI+4XhLRHxE5FyItJURHo7ETci0sXxuyqPbRtKx3b5PnOtJoUc/hHwsog0d/yuQ0Uk0JnrqvPTROGBjDEJwH+BZ40x0cBg7A00AfvN6zH++t3fia0734mtTx/vOEc4cC+2KuA4tgF5ZCGXXQA0B44YYzbnieUb4HVgnqNaYxtw9QW8l13Yxtn3gERgELYr8Ok8u32GvUFFOX4mX8x7MMZEAm8Ba7A3pnbYxvEzlgHbgcMikujse8jjIWw10GHgE+BzbNIrKJaD2LaHidjqughsA+35LMEm/93Yarh0Cq/iAvgntiSYgk2uZxItxpgUbEeCQY649wB9HZv/5/j3qIhsdDy+C/ABIrGf+ZfYak5n+Dmuf9wR+1H+Khl/DLR2VGl9W8Cx/8Z+qfgJm/Q+xjaWqyKgA+5UqSZ2sOE9xpil7o7lQonI60BtY8wId8eiVGG0RKFUMRGREEeViIhIV+Bu4Bt3x6XU+ejISKWKjy+2uqkutprvLeA7t0aklBO06kkppVShtOpJKaVUoUpd1VONGjVMo0aN3B2GUkqVKhs2bEg0xtS8mGNLXaJo1KgR4eHh7g5DKaVKFRE5cP69CqZVT0oppQqliUIppVShNFEopZQqlCYKpZRShdJEoZRSqlCaKJRSShXKZYlCRGY51r7ddo7tIiJTRWSv2LVxO7oqFqWUUhfPlSWKOcDAQrZfjZ2WujlwH3bxFKWUUkUsO+fSpmpy2YA7Y8wKEWlUyC6Dgf86VkJbKyLVRKSOY/ETpZRSFyEhJYOdh5PZeSiFHYeT8V65kgE/fXb+AwvhzpHZ9fj7gioxjtfOShQich+21EGDBg2KJTillCrJMrKy2Rufys5DKTYxHE5hx6FkElPtml7VTybx0qo5XLfpZ07UqneesxXOnYlCCnitwPKRMWYmMBOgc+fOOt2tUqpMScvIYnPMCXYdTiEi+gQ7DiXzZ0JabpWSj3c5WtbypW/LIELq+NGqti+dJ96Lz9bl8OSTVHvmGahS5aKv785EEcPfF5cPBuLcFItSSpUIp05nE3komW2xSWyOOUFE9An2JaZxZkWIIN8KtKvnz5WtaxFS249WdfxoFFgZb69ysH07VPOBejXgrTfhX5OhTZtLjsmdiWIB8JCIzAO6AUnaPqGUKktOZ+WwNTaJbbFJuf/uiU/NLSnUqOpD+/oBXB9Wl/b1q9Gqjh9BvhUQyVchk5YGL78Mb70Fw4fDnDnQrFmRxemyRCEinwN9gBoiEgM8D5QHMMbMAH7ALh6/FzgJjHJVLEop5W7GGGKOnyLyUDJbY5JYv/8YEdEnyMjKASCwig/tgm1JoW09f9rV86eOf8Wzk0J+338PY8fCgQMwejS8/nqRx+7KXk+3n2e7Aca66vpKKeUOxhgSUjLYfSSVPfEpHDh6ksi4ZHYcTiYlPQsAr3JC6zp+DO/WkK6NqxNW35/afk4khfzef98midatYcUK6NXLBe+oFK5HoZRSJUVmtq062hqTxL7ENLbHJbHzcEpuQgCo4uNFs1q+DG5fl5a1/Whb14+Q2n5U8vG6uItmZUFCAtSpA7fcAqdOwbhx4ONTRO/qbJoolFLKCfHJ6UQeSmZfYhpbY5KIPJTM3vhUshztCZV9vGhVx48h7evRvFZVmtWsSvNavtSo6nPhJYVzWbcO7r8fvL1h7VqoUQMmTiyacxdCE4VSSjkYY4hPySAyLpk98SnsS0wjKiGNfYlpxKdk5O5Xo6oPber60zckiNZ1/OjauHrBjcxF5cQJeOopmDHDliTefRfKFd9UfZoolFJljjGGw8npbI5OYs+RFPYfPcn+o2n8mZDKiZOZuftVr+JDkxpV6NW8Jq3q+BIaXI1GgZUJ8qtYfMFu3QpXXmmrmx5+GF56Cfz8iu/6aKJQSnm4+JR09hxJZf/RNLbHJbPd0QX15Ons3H1q+1WkYWBlrm5bm5a1fGlVx4+WtX2pVtl19f7nlZkJ5ctDixbQty889hh0dM/cqZoolFIeIT3TTmmx41AyUYk2KUTGJZOY+leVkV9Fb9rU9eeWzvVpUrMKbev5E1Lbl8o+JehWmJFhu7h++ils3AhVq8Lnn7s1pBL06SillHPOjF7edPA4m6JPEBmXzIGjaZyZJNW7nNC8li+9W9gqo9Z1/agfUJnggEqua0coCsuWwQMPwO7dcOutNmlUreruqDRRKKVKtrSMLP5MSCUyLtkxpUUSu4+k5I5erletEu3q+XN9WF1a1valZW1fGlSvTHmvUrQu26lTcN99thTRpAksXgxXXeXuqHJpolBKlRinTmezPS6JzTFJbI4+wba4JPYn/lVS8KvoTVj9avRv1ZS29fzpUL9a8TYsu0rFipCYCM88Y3s3Vark7oj+RhOFUsotMrKy2R5np7PYGpvE9rjkv5UU6vpXpG09fwaF1qV1XT+aB1WlcY0qJbvq6EJs2WIbqD/+GIKD7VQcxdjl9UJoolBKuZwxhrikdDYeOM6mgyfYFH2c7bHJnM628xzVqOpD67r+9G8VRGhwNcKC/T2jpFCQtDR44QV4+20ICIA9e2yiKKFJAjRRKKVcID0zmy0xSbax+eAJNh48njtgrWL5coTWq8aono3oUD/g4uc5Ko0WLLDTbRw8CPfeC6+9BtWruzuq89JEoZS6ZOmZ2UREn+DnyCOs23eMHYeSc6e2aBhYmX80q0GHBtXoUD+AkDq+pauhuSh9+60dLLdqFfzjH+6OxmmaKJRSFywrO4ctsUms+fMoa6OOsn7/MdIzc/DxLkfnhgHc37sJHeoH0KFBNQKrVnB3uO6TmQlTp9oBcx072qk3Kla0A+lKEU0USqnzyszOYXP0CdbtP8b6fcdYt+8YaY6RzS1r+XJblwZc1jSQHk0D8a1Yum6CLrN2rZ3Ab8sWeOIJmyh8fd0d1UXRRKGUOsuZ6bN/25XA+v3H2HjwOOmZtuG5ac0q3NCxHj2a1KB7k+plu8RQkOPH4cknYeZMqFcPvvkGBg92d1SXRBOFUoqs7Bx2HUlh1Z5EVu1NZN2+Y2Rk5VBOoHVdP27v2oAujarTo0kgAVXcOP9RaTBzJnz0EUyYYHs3ldJSRF6aKJQqo6KPnWTFngT+iDrGr7viSXYsttM8qCq3d21Ap4YB9Gpew70T45UWu3bZ2V179oTx4+HqqyE01N1RFRlNFEqVEWkZWayNOsqqvYn8vvcou46kABDkW4H+rWvRq3kNejSpQW1/Dx2/4Arp6fDqq7aba0gIRERAhQoelSRAE4VSHutMl9Xw/cdYsSeRiOgTnM7KoYJ3Obo0qs5NnYLpGxJE05oeNNq5OP38Mzz4IOzdC8OGwVtvgYd+jpoolPIQmdk57Dqcwpo/j7JiT0JuOwNA23p+jOjRkD4tg+jUMICK5S9yvWZlrVgBAwZA8+Y2YfTv7+6IXEoThVKlVHaOYefhZNZGHWPNn4ms+fNobpfV5kFVGd6tIZc1DaRTwwBtgC4K2dkQGQnt2kGvXnaOpmHD7LgID6eJQqlSJD45ndV/JrJsZwKr9iRw3LFsZ4PqlRnSoR7dm9jEULdayZp9tNTbtAnGjIEdO+zcTLVqwejR7o6q2GiiUKoES07PZMOB4/wRdYyVexLYHpcM2En0+oYE0at5Dbo2DqSeJgbXSEmB55+3I6pr1IAPPoCgIHdHVew0UShVghhjOHjsJIu3HeaXHfGEHzhGjoHyXkKH+gE8PrAlvZrVpE1dP8qV88yG0xIjKclWM0VH2xHWr75qZ3stgzRRKOVm6ZnZ/LHvGIu3HWbF7gRiT5wCoHUdPx7s04weTQNpX78aVSrof9dikZxsJ+7z97erzl1xBfTo4e6o3Er/8pRyg/jkdJbtjGfpjiOs2ptIemYOVXy86Nm8BmN6N6F3iyAaBFZ2d5hlS2amXSNi8mT49Vc7N9Mzz7g7qhJBE4VSxcAYw64jKSzZdoRlu+LZEnMCY+x6z7d2rk+flkH0aBqo3VbdZfVq21i9bRsMGQI1a7o7ohJFE4VSLmKMYXtcMst2xvNtRCxRCWmIQPv61ZjQvwVXtq5FSG1fHezmbuPGwbRpUL8+fPcdXH+9uyMqcTRRKFWEkk5m8uvueFbuSWTF7gTiUzIQgS6NqjP6H425qk1tavrqbKtuZ8xfo6hr14Z//tP2bqpa1b1xlVCaKJS6RPEp6SzZdpgl24+wNuooWTkGv4reXN6iJpe3qEmfFjU9d/3n0mjnTlvNNGGCnf776afdHVGJp4lCqYsQe+IUP28/zOLth1m3z3ZhbVKjCvf0asKANrUIC66Gl3ZfLVlOnYJ//Qtefx2qVLHPlVNcmihEZCDwLuAFfGSMeS3fdn/gU6CBI5YpxpjZroxJqYt1LO00i7bE8cPWQ6yNOgZAi1pVebBPM65vX5fmQVW1vaGk+uUXOxbizz/hzjthypQyOXDuYrksUYiIFzAduBKIAdaLyAJjTGSe3cYCkcaYQSJSE9glInONMaddFZdSFyIjK5tfdyXwv/AYlu+KJzvH0LRmFSb0b8GgsDo0qal12qVCTAx4e9uE0a+fu6MpdVxZougK7DXGRAGIyDxgMJA3URjAV+zXsKrAMSDLhTEpdV7ZOYZNB4/z1cZYFm2JIyU9iyDfCtzdszFDO9YjpLafu0NU55OdDTNmgI8P3Hsv3HUX3HabXStCXTBXJop6QHSe5zFAt3z7TAMWAHGAL3CrMSYn/4lE5D7gPoAGDRq4JFiltsclMX99NN9vPURi6mkqlffi6ra1uS6sDr2a16S8Vzl3h6icsXGjrWYKD4cbb7SJQkSTxCVwZaIoqLLW5Ht+FRAB9AOaAj+LyEpjTPLfDjJmJjAToHPnzvnPodRFO5KczncRsXy7KY7IQ8lU8C5Hv5AgBratTd+QIPwqlnd3iMpZycnw7LN2TETNmvD553Drre6OyiO4MlHEAPXzPA/GlhzyGgW8ZowxwF4R2QeEAOtcGJcq4zKzc1i2M57P1x3kt90JGANh9avx4vVtGNy+rq4RXVpt3myTxJgx8MorUK2auyPyGK5MFOuB5iLSGIgFbgOG5dvnIHAFsFJEagEtgSgXxqTKKGMM22KT+Xz9QX7afpjE1NPU8a/Ig32aMrRjME21Ubp02rcPli+3a0P06mWXJW3c2N1ReRyXJQpjTJaIPAQswXaPnWWM2S4iYxzbZwAvA3NEZCu2quoJY0yiq2JSZU/M8ZN8sT6ahZvj2H/0JJXKe9EvJIjB7evSNyRI2x1Kq9On7RrVL71kV5i74QY7BbgmCZdw6TgKY8wPwA/5XpuR53EcMMCVMaiyJys7h193JTBvfTTLdh4B4LKmNbjv8qZc264O/pW13aFUW7nSVi9FRsLQoXZRoTK6TkRx0ZHZymMcTc3gi/BoPl1zgLikdGpU9eGBPk0Z1q2hrgDnKRISYMAAuxTpwoVw3XXujqhM0EShSr298Sl8vGofX22I5XR2Dj2aBPLcoNZc0aqWVi15AmNg6VK48krbm2nRIuje3U7DoYqFJgpVKhljWLEnkenL97Ju3zF8vMpxY6dg7u7ZiGZBvu4OTxWV7dvhgQdsddPy5dCnj11xThUrTRSqVDmdlcPi7YeZvmwvu46kUMe/Ik8MDOHmzsHUqKoDqjzGyZN2pbk337TLkn70EVx+ubujKrM0UahSIelUJp+s2c/cPw5yKCmdJjWr8OZNoVzfvi4VvHVVOI9iDPTtC+vWwYgRNlnoinNupYlClWjJ6ZnMXrWfWav3kXQqk57NavDy4Lb0CwminE7j7VkOHbIzunp5wVNPgb+/rWpSbqeJQpVIx9NO8+GKKD5de4DUjCyuCAni0QEtaFPX392hqaKWnQ3Tp8Mzz9gR1ePG2QWFVImhiUKVKCdOnua/aw7w0cooUjKyuLZdHe6/vCntgjVBeKTwcDuB38aNcNVVcM017o5IFcDpRCEiVYwxaa4MRpVdyemZzFq1j/+siCLtdDb9WwXxz6ta6pTenuyNN2DSJLtm9RdfwM03/7WOtSpRzpsoROQy4CPsehENRCQMuN8Y86Crg1OeLzUji7lrD/CflVEkpp5mYJvaPNK/Oa3qaILwSMZAVhaULw9du8LYsbZ3k7+WGEsyZ0oUb2OnA18AYIzZLCLaT01dkvTMbGav3s/Hq2yCuKxpIB+PCCGsvs746bH+/BMefBDatrXzNPXpo43VpYRTVU/GmOh8awFnuyYc5emMMSzbGc+LCyM5eOwkPZvV4NEBLejYQOfq8VgZGbaL6yuv2JKENlSXOs4kimhH9ZMRER/gYWCHa8NSnuZMgnh76W62xSbTuEYVPr27Gz2b13B3aMqVNmyAO+6AnTttG8Q770Dduu6OSl0gZxLFGOBd7NKmMcBPgLZPKKeF7z/Gm0t28ce+YzSoXplXh7bjxo7B+HjrPEwer2pV20D9ww9w9dXujkZdJGcSRUtjzPC8L4jIP4DVrglJeYpdh1N4ffFOlu2Mp6ZvBV4Y1Jph3RpqgvBkOTkwezasWWOn3WjZErZtg3L6Oy/NnEkU7wEdnXhNKQASUzOYtmwvn6w9QGUfLx67qiWj/tGIyj46bMejbdtm14lYvdrOy5SWZmd41SRR6p3zf66I9AAuA2qKyKN5NvlhV6xT6m/SM7OZtXof05ft5VRmNrd1bcBjA1oSUEXXoPZoaWl2pbl//9t2c509287RpGMiPEZhX/F8sGMnvIG88zYnAze5MihVuuTkGL7bHMubi3cRl5TOFSFBPHlNK5oF6TrUZUJ6uk0Od91lB9EFBro7IlXEzpkojDG/Ab+JyBxjzIFijEmVIpsOHufZ77axLTaZdvX8mXJzGJc1055MHi8mBqZOhVdftYlh506oXt3dUSkXcabS+KSIvAm0ASqeedEY089lUakS72hqBu/+sodP1x4gyLcib90cxg0d6umMrp4uKwveew+ee85O5nfrrdCpkyYJD+dMopgLfAFch+0qOwJIcGVQquQyxrBwyyFeWLCd5FOZDOvWgCcGhuBbsby7Q1Ou9scfdgK/zZvt5H3TpkHjxu6OShUDZxJFoDHmYxF5JE911G+uDkyVPNHHTvLiwkiW7jhCaLA/b97bnZa1ddnRMiEnB0aNgqQk+PJLGDpUG6vLEGcSRabj30Mici0QBwS7LiRV0pzOymHGb3/ywa9/AvDUNSHc3bMJXlrN5NmMsUlh4EDw9YWvv4Z69exjVaY4kygmi4g/MBE7fsIPGO/SqFSJsTc+hfFfRLAtNpmr29bmmetaU69aJXeHpVxtzx47s+vPP8OUKTBxIoSEuDsq5SbnTRTGmEWOh0lAX8gdma08mDGGz9Yd5KWFkVSp4M2MOzoysG0dd4elXC0jA15/Hf71L6hQwbZDjBnj7qiUmxU24M4LuAU7x9NiY8w2EbkOeAqoBHQonhBVcUtIyeDpb7byU+QRejarwb9vDSPIt+L5D1Sl39ix8PHHcNttdgBdHf1yoAovUXwM1AfWAVNF5ADQA5hkjPm2OIJTxW/h5jie+24baaezeeqaEO7p2US7vHq6+HjbWF27NjzxhJ3l9aqr3B2VKkEKSxSdgVBjTI6IVAQSgWbGmMPFE5oqTinpmby8KJL54TG0r1+NN28KpXktbbT0aDk5duK+J56AAQPscqTNm9sfpfIoLFGcNsbkABhj0kVktyYJz7R+/zEmzt9MzPGTPNinKY9e2QJvL53IzaNt2WLbHtassavMvfiiuyNSJVhhiSJERLY4HgvQ1PFcAGOMCXV5dMqlcnIM/1kZxeuLd1K3WiW+uL8HXRrpCFuP9+WXtg0iIAD++1+7sJCOiVCFKCxRtCq2KFSxiz1xise/3MzqvUe5pl1t3rgpjKoVdBpwj5acDH5+tgQxdiw8/7xOvaGcUtikgDoRoIf6dlMsz363jewcw+QhbRnerQGi3yg918GDMG4cxMXB2rVQowa8+667o1KliEsrokVkoIjsEpG9IjLpHPv0EZEIEdmuU4O41qnT2TwybxPjv4igac2qLH7kcu7o3lCThKfKzLSD5Vq1gqVL4ZZb7GhrpS6Qy+oaHOMwpgNXYtfaXi8iC4wxkXn2qQa8Dww0xhwUkSBXxVPWHUo6xT3/F07koWQm9G/B2L5NtcHakx04ANdfbxutBw2yM742bOjuqFQp5VSiEJFKQANjzK4LOHdXYK8xJspxjnnAYCAyzz7DgK+NMQcBjDHxF3B+5aQVuxN4dH4E6Zk5fHRXZ65oVcvdISlXMcY2TNeuDbVqwTffwODB2litLsl5v1KKyCAgAljseN5eRBY4ce56QHSe5zGO1/JqAQSIyK8iskFE7nIubOUMYwzv/bKHu2atI6CyD988eJkmCU9lDHz6KXTpAqmpdvqNn36CIUM0SahL5kzdwwvY0sEJAGNMBNDIieMK+uvMX0HqDXQCrgWuAp4VkRZnnUjkPhEJF5HwhARdCsMZGVnZPDp/M2/9vJsh7euycFxPHUDnqXbtgiuugDvvBG9vOHrU3REpD+NMosgyxiRdxLljsFOAnBGMnaI8/z6LjTFpxphEYAUQlv9ExpiZxpjOxpjONWvWvIhQylmrLScAACAASURBVJaElAxum7mWbzbFMvHKFrx9a3sqlvdyd1iqqGVl2S6uoaGwcSN88AH8/ru2Ragi50yi2CYiwwAvEWkuIu8Bvztx3HqguYg0FhEf4DYgf5XVd0AvEfEWkcpAN2DHBcSv8tkcfYLB01ax41Ay04d1ZNwVzbVXk6fy8oKVK+Gmm2ypYswYKKcdFFTRc+avahx2vewM4DPsdOPnXY/CGJMFPAQswd785xtjtovIGBEZ49hnB7btYwt28sGPjDHbLuaNKPhyQww3f7gGEeF/91/GtaE686fHOXwYRo+G6Gjb9vDDDzB3rm24VspFxJynX7WIdDDGbCqmeM6rc+fOJjw83N1hlCg5OYYPfvuTN5fs4rKmgUwb1pHqVXzcHZYqStnZMHMmPPkknDplG65vvtndUalSREQ2GGM6X8yxznSP/beI1AH+B8wzxmy/mAsp10jNyOKf8zezePthrg+ry5Sbw/Dx1uoHj7Jpk61WWrfONlq//z60OKvPh1Iu48wKd31FpDZ2EaOZIuIHfGGMmezy6FShjqZmMGL2OiLjknn6mlbc06uxtkd4omnTYP9+W8V0++3a3VUVu/NWPf1tZ5F2wOPArcYYt9RtaNWTFRmXzN3/t56jqaeZcWdH+oVoHbXHMAa+/RYaNYIOHeD4cft6QIBbw1Kl26VUPTkz4K6ViLwgItuAadgeT8EXczFVNLbFJnHrzDUYA189cJkmCU+yf7+demPoUHjnHftaQIAmCeVWzrRRzAY+BwYYY/KPg1DFbMOB44yesx6/iuWZd1936lev7O6QVFHIzLRrVL/4ou3iOmUKPPKIu6NSCnCujaJ7cQSizm/ZziM8OHcjtf0q8snd3TRJeJIPP4RJk+yUG+++Cw0auDsipXKdM1GIyHxjzC0ispW/T72hK9y5weJthxj3+SZCavsxa2QXavpWcHdI6lIdPWqrmjp1gnvvhWbNYOBAd0el1FkKK1GcKfdeVxyBqHP7ZlMME+dvJqx+NeaM6op/pfLuDkldCmPsEqT//Cf4+sLu3XYSP00SqoQ6Z2O2MeaQ4+GDxpgDeX+AB4snPPXJ2gM8On8z3RoHMveebpokSrsdO6BvXxg5Epo3t72bvHUJWlWyOTMy68oCXru6qANRZ5u1ah/PfruNfi2DmD2qC5V99IZSqm3eDGFhdjGhmTNh1So7oZ9SJVxhbRQPYEsOTURkS55NvsBqVwdW1s1ZvY+XFkVyVZtavHd7Rx1tXZrFxEBwsE0KL74Id98NQbqYoyo9CvuK+hnwI/AqkHe96xRjzDGXRlXG/XfNfl5YGMmVrWsxbVhHyuuSpaVTXBxMmGAn7tu5E+rVs3M1KVXKFHYHMsaY/cBYICXPDyJS3fWhlU2frNnPc99tp3+rWkwb1kGTRGmUnW2n3WjVCr77Dh5/HGrUcHdUSl2085UorgM2YLvH5p1gxgBNXBhXmbR42yGe/W47/VsFMX14Byp462JDpU56Olx+OaxfD1deaSfwa9bM3VEpdUnOmSiMMdc5/m1cfOGUXev3H+PheRG0r1+NacM6apIobTIzoXx5qFjR9mp69FG49VadwE95BGfmevqHiFRxPL5DRP4tIjpstAhtPHicUbPXU69aJWaP7KLLlpYmxsCXX9pSw8aN9rXXX4fbbtMkoTyGMxXgHwAnRSQMO3PsAeATl0ZVhmyOPsFdH6+jehUfPru3GwG64FDpERUF115rFxAKDNRlSJXHcuYvO8vYucgHA+8aY97FdpFVlyj62Enu+W84/pXK88X93anjX8ndISln/fvf0KaNXbP6nXfsokLt27s7KqVcwpkRXCki8iRwJ9BLRLwAHR58iQ4npTP8oz9Iz8xm7j3dNEmUNqmpcM01dgK/YJ11X3k2Z0oUtwIZwGhjzGGgHvCmS6PycHvjUxn6/mqOpmbwyd3daFFLC2glXmIijBoFCxbY5888A199pUlClQnnTRSO5DAX8BeR64B0Y8x/XR6ZhzqamsGIWes4nZ3DF/f3oH39au4OSRUmJwdmzYKWLeHTT2HvXvu6tkeoMsSZXk+3AOuAm7HrZv8hIje5OjBPlJWdw4NzN5KYmsHHI7rQtp6/u0NShYmMhD597JQbrVtDRITt9qpUGeNMG8XTQBdjTDyAiNQElgJfujIwT/TmT7v4Y98x3ro5jDAtSZR84eGwfTt8/LGd7VVLEaqMciZRlDuTJByO4lzbhsrji/UH+fC3KIZ1a8CNnbReu8T64Qe7oNCdd9qf666D6jpjjSrbnLnhLxaRJSIyUkRGAt8DP7g2LM+yem8iz3y7jV7Na/Di9W3cHY4qSEwM3HSTHRcxbZodSCeiSUIpnGvMfgz4EAgFwoCZxpgnXB2Yp4g9cYpxn2+iUWAVnQm2JMrKsl1cW7WC77+HV16xYyN0VLVSuQpbj6I5MAVoCmwF/mmMiS2uwDxBemY2D366gdNZOcy4s5OuTlcSbdgA48fbZUinT4cmOtelUvkV9vV2FrAIuBE7g+x7xRKRhzDG8NQ3W9kck8Rbt4TRtGZVd4ekzkhKgq+/to+7dYM//rBtE5oklCpQYY3ZvsaY/zge7xKRjcURkKf4eNU+vt4Yy/j+zbmqTW13h6PAtjvMn29LEEePwv79ULcudO3q7siUKtEKSxQVRaQDf61DUSnvc2OMJo5zWL4znld+2MHANrV5uF9zd4ejAP78E8aOhSVLoFMnWLjQJgml1HkVligOAf/O8/xwnucG6OeqoEqzA0fTeGTeJkJq+/H2re0pV04bRd0uJcUmh5wcmDoVHnwQvHQqd6WcVdjCRX2LMxBPkJ6ZzbjPNwHw4R2dqOSjNyO32rIFQkPB19cOmuve3a5brZS6INpXswi98v0OtsQk8ebNYTQIrOzucMquhAQYMQLCwmwjNcCNN2qSUOoiuTRRiMhAEdklIntFZFIh+3URkezSPIfUsp1H+GTtAe7p2Vgbr90lJwc++shO4Pf55/DUU3auJqXUJXFmCo+L4li3YjpwJRADrBeRBcaYyAL2ex1Y4qpYXC0hJYOJ8zfTqo4f/7yqpbvDKbtuvBG+/RYuvxw++MBO5KeUumTOzB4rjrWyn3M8byAizvQn7ArsNcZEGWNOA/Owq+TlNw74CogvYFuJd2a8RGpGFlNva6/rXRe3tDQ7uhrg9tthzhz49VdNEkoVIWeqnt4HegC3O56nYEsK51MPiM7zPMbxWi4RqQfcAMwo7EQicp+IhItIeEJCghOXLj6fr4vm58gjPH5VCM11AaLitXChTQjvv2+f33KLbZvQ6TeUKlLOJIpuxpixQDqAMeY44OPEcQX9bzX5nr8DPGGMyS7sRMaYmcaYzsaYzjVr1nTi0sVj95EUXliwnX80C+Tuno3dHU7ZER0NQ4fC9dfbHk2dOrk7IqU8mjNtFJmOdgQDuetR5DhxXAxQP8/zYCAu3z6dgXlivwHWAK4RkSxjzLdOnN+tMrNzeHR+BFUrevPubR10vERx+fRTGDPGNly/9hpMmAA+znxvUUpdLGcSxVTgGyBIRF4BbgKeceK49UBzEWkMxAK3AcPy7mCMyf0aLiJzgEWlIUkAvLlkF9tik3l/eEdqVK3g7nA835lpv4ODbU+m996DxlqKU6o4nDdRGGPmisgG4ApsddIQY8wOJ47LEpGHsL2ZvIBZxpjtIjLGsb3QdomSbPXeRGauiGJ4twZc066Ou8PxbCdOwJNPQpUqMGWKTRLa5VWpYnXeRCEiDYCTwMK8rxljDp7vWGPMD+Rb5OhcCcIYM/J85ysJElIyeGTeJprUrMLT17Zydzieyxg7FuLRR+0AugkT/ipVKKWKlTNVT99j2ycEqAg0BnYBZW6ptpwcw6SvtpCcnsXce7pT2cdlw1DKtn374L77YOlS6NIFfvwROnRwd1RKlVnOVD21y/tcRDoC97ssohJs5sooftkZz/ODWtOytnaFdZnMTDtP0/TpcP/9OoGfUm52wV+JjTEbRaSLK4IpyXYdTuGtn3ZxddvajLyskbvD8Ty//GKXIv33v6FFCzhwACpWdHdUSimca6N4NM/TckBHoGSNenOx01k5jP8iAt+K5Zk8pC2i9eRF58gRmDgR5s6Fpk3h6achMFCThFIliDMD7nzz/FTAtlkUNBWHx/rPyih2HErmtaHtCNSusEUjJwc+/BBCQuyqc88+C1u32iShlCpRCi1ROAbaVTXGPFZM8ZQ4UQmpTP1lDwPb1ObK1rXcHY7nSEqCZ56B9u3tBH4hIe6OSCl1DucsUYiIt2NqjY7FGE+JYozhya+34uNdjpcGt9Eqp0uVmmrbILKzISAA/vgDli3TJKFUCVdYiWIdNklEiMgC4H9A2pmNxpivXRyb232+Lpo/9h3j1aHtCPLTOvNL8t13MG6cnaepfXvo1w+aNHF3VEopJzjTRlEdOIpdI/s6YJDjX4924uRp3lyyk66Nq3Nbl/rnP0AV7MABGDwYhgyBatVg9WqbJJRSpUZhJYogR4+nbfw14O6M/LPAepzXF+8iOT2LF6/XKqeLZgzcdBNERsIbb8D48VC+vLujUkpdoMIShRdQFeemC/co2+OSmLf+ICMva0SrOn7uDqf0WbsW2rSxU4DPnAnVq0PDhu6OSil1kQpLFIeMMS8VWyQlRE6O4bnvtlOtUnnG92/h7nBKl2PH7AR+M2fCc8/Biy/q1BtKeYDCEkWZrG/5NiKWDQeO88aNofhX0moSpxhj14mYONEmi4kT4bEy26NaKY9TWKK4otiiKCFS0jN57cedhAX7c1OnYHeHU3o89ZRdRKh7d/j5ZwgLc3dESqkidM5EYYw5VpyBlASvL95JQmoGH97ZSVesO5/0dDsuokYNGDXKtkHcdx+Uc6YjnVKqNNH/1Q47DiUz94+DjOjRiA4NAtwdTsn288/Qrh3ce6993qKFXZ5Uk4RSHkn/Z2NHYD/77Tb8K5VnfP/m7g6n5Dp8GIYNgwED7AJCDz3k7oiUUsVAV94Blu+KJ/zAcV4d2o5qlX3cHU7JtHw53HADnDoFL7wATzyhM7wqVUaU+USRk2N4Y/EuggMqcWNHbcA+S2amHSQXGgpXXgmvvGKrmpRSZUaZr3patPUQOw+n8NhVLfHxLvMfx19SUuw61b162Un8AgPhf//TJKFUGVSm74zpmdm8/uNOQmr7Mii0rrvDKRmMga+/hlat4N137YC5jAx3R6WUcqMynSg+++MgsSdO8cy1rbU7LEBiIgwaBDfeaLu9/v67XSuicmV3R6aUcqMymyiSTmYyddkeLmsayD+a6apqgJ2b6cgRu2ZEeLgdQKeUKvPKbKKYtXofJ05m8tQ1rcr27LCrVsHVV9vBcxUq2MWEJkwA7zLfz0Ep5VAmE0V8SjofrYzi6ra1aVvP393huMfRo3DPPbaxOjISoqLs6zpoTimVT5m8K7yzdA+ns3N4fGAZXILTGJgzB1q2tP8+9phNFKGh7o5MKVVClbn6hZjjJ/lfeDS3dK5P4xpV3B2Oe/z3vzZRzJhhp+JQSqlClLkSxQe//okgjO3bzN2hFJ9Tp+D55yEmxk698dVXsHKlJgmllFPKVKKIT0nnyw0x3NChHnWrVXJ3OMVjyRJo2xZeegm++86+FhCgbRFKKaeVqbvFRyv3kZVjeKBPU3eH4npxcXDrrTBwoJ2CY9kyGDvW3VEppUqhMpMoUtIz+XzdQQa2rU2jstA2MXmyLUG89BJs3gx9+7o7IqVUKVVmGrP/syKKlPQsHujtwaWJDRv+msDv5Zfh0UehWRlqi1FKuYRLSxQiMlBEdonIXhGZVMD24SKyxfHzu4i4ZA3NpJOZzF6933PHTSQnw8MPQ9eudllSsJP4aZJQShUBlyUKEfECpgNXA62B20Wkdb7d9gG9jTGhwMvATFfEMvv3faRkZPFQPw+7cRpjZ3QNCYFp0+CBB+DTT90dlVLKw7iy6qkrsNcYEwUgIvOAwUDkmR2MMb/n2X8tUOQLQqSkZ/Lxyn0MaF2LNnU9rDTx2Wdwxx12htfvvoMuXdwdkVLKA7kyUdQDovM8jwG6FbL/3cCPBW0QkfuA+wAaNGhwQUHMXr3fs0oTp0/b6TZCQuCmm+wYiZEjdW4mpZTLuLKNoqCZ9kyBO4r0xSaKJwraboyZaYzpbIzpXLNmTacDSM3I4uNV++jfqhahwdWcPq7EWrEC2re3a1anp9tJ/O65R5OEUsqlXJkoYoD6eZ4HA3H5dxKRUOAjYLAx5mhRBjBn9T6STmUyrrSXJhITYdQo6N3bliBmzND1qpVSxcaVX0XXA81FpDEQC9wGDMu7g4g0AL4G7jTG7C7Ki6dnZvPxqn30CwkirH4pLk1ERdm2h+RkmDQJnn1WFxJSShUrlyUKY0yWiDwELAG8gFnGmO0iMsaxfQbwHBAIvO9YEyLLGNO5KK7/w9ZDHD+ZyT09GxfF6YpfcjL4+UHjxrY0MXKknYpDKaWKmRhTYLNBidW5c2cTHh5+3v2ueXclaaezWD6xT+la5vTkSTtYbuZMO6I6uMg7gimlyiAR2XCxX8Q9cgqPzdEniDyUzG1dGpSuJPH999CmDbz2GgweDJXKyMSFSqkSzSO7y3y69gA+3uUY3v3CutK6TVYW3H47fPkltGoFv/0Gl1/u7qiUUgrwwBJF0qlMFm6J48aO9fCrWN7d4RTuTLWftzfUqgX/+hdERGiSUEqVKB6XKL7aEEN6Zg53dG/o7lAKt349dOsGGzfa59OmwZNPgo+Pe+NSSql8PCpRGGP434YY2tT1K7nTdSQlwUMP2SQREwNHi3ToiFJKFTmPShSRh5LZcSiZW7vUP//O7nBmAr8PPrDJYudOuPJKd0ellFKF8qjG7M/XHcTHuxyDQuu6O5SC7dgB9erBwoXQuUiGiyillMt5TIkiPTOb7zbFcW27OgRUKSH1/BkZdqW5hQvt8yefhD/+0CShlCpVPCZRLN1xhJSMLG7qVEIGqC1fDmFhdsqNX36xr5UvD15e7o1LKaUukMckiv+Fx1DHvyLdmwS6N5D4eBgxAvr1g8xM+PFHeOcd98aklFKXwCMSRUJKBiv3JDC0Yz283D0S+6ef4PPP4emnYds2GDjQvfEopdQl8ojG7B+3HSLHwKAwNzVib90Ku3bZhYSGD4fLLoMmTdwTi1JKFTGPKFEs3BxHy1q+hNT2K94Lp6XB44/bpUgff9xWNYloklBKeZRSX6I4nJRO+IHjjL+iRfFeeOFCOxbi4EG4+254/XXbWK1cKjMzk5iYGNLT090dilIlUsWKFQkODqZ8Ed6PSn2iWLg5DmPgurA6xXfRbdvg+uvtTK8rV0LPnsV37TIuJiYGX19fGjVqhGMNE6WUgzGGo0ePEhMTQ+PGRbcWT6mvelqwOY6wYH+a1qzq2gtlZcGvv9rHbdvCokWwaZMmiWKWnp5OYGCgJgmlCiAiBAYGFnmJu1QnivjkdLbGJnFl61quvdCZQXJXXAF79tjXrr1Wq5rcRJOEUufmiv8fpTpR/LY7AYB+IS5KFMePwwMPQI8ekJho52pq1sw111JKqRKqVCeK5bviCfKtQEht36I/eUaG7c00cyaMH2/naRo61PZqUmVa1aqXXs0ZHh7Oww8/fM7t+/fv57PPPnN6//z69OlDy5YtCQsLo0uXLkRERFxSvEVpwYIFvPbaa0VyrlOnTtG7d2+ys7OL5Hyu8Oqrr9KsWTNatmzJkiVLzrnfe++9R8uWLWnTpg2PP/44YP8OKlWqRPv27Wnfvj1jxozJ3b9///4cP37c5fEDtvGjNP106tTJGGNMZla2aff8YvPY/yJMkYqJ+evx7NnGbNxYtOdXlyQyMtLdIZgqVaq4/BrLly8311577UUf37t3b7N+/XpjjDGzZs0y/fv3L5K4srKyiuQ8RWXatGnmnXfecXr/nJwck52d7cKI/m779u0mNDTUpKenm6ioKNOkSZMCP8Nly5aZK664wqSnpxtjjDly5Igxxph9+/aZNm3aFHjuOXPmmMmTJxe4raD/J0C4ucj7bqnt9bQ9Lpnk9Cx6Nq9ZNCdMT7ddXP/1L5g/365ZPXJk0ZxbucSLC7cTGZdcpOdsXdeP5we1ueDjIiIiGDNmDCdPnqRp06bMmjWLgIAA1q9fz913302VKlXo2bMnP/74I9u2bePXX39lypQpLFq0iN9++41HHnkEsPXLK1asYNKkSezYsYP27dszYsQIOnTokLt/amoq48aNIzw8HBHh+eef58YbbzxnbD169ODNN98EIC0tjXHjxrF161aysrJ44YUXGDx4MCdPnmTkyJHs3LmTVq1asX//fqZPn07nzp2pWrUqjz76KEuWLOGtt95i//79TJ06ldOnT9OtWzfef/99AO6+++7cmEaPHs2ECROYOnUqM2bMwNvbm9atWzNv3jzmzJlDeHg406ZN48CBA4wePZqEhARq1qzJ7NmzadCgASNHjsTPz4/w8HAOHz7MG2+8wU033XTWe5s7d25uySs1NZXBgwdz/PhxMjMzmTx5MoMHD2b//v1cffXV9O3blzVr1vDtt98yf/585s+fT0ZGBjfccAMvvvgiAEOGDCE6Opr09HQeeeQR7rvvvgv+W8jru+++47bbbqNChQo0btyYZs2asW7dOnr06PG3/T744AMmTZpEhQoVAAgKCjrvua+//np69erF008/fUkxOqPUVj2t23cMgO6Nq1/6yX75BUJD4YUX4MYb7aJCSl2Au+66i9dff50tW7bQrl273BvPqFGjmDFjBmvWrMHrHBNCTpkyhenTpxMREcHKlSupVKkSr732Gr169SIiIoIJEyb8bf+XX34Zf39/tm7dypYtW+jXr1+hsS1evJghQ4YA8Morr9CvXz/Wr1/P8uXLeeyxx0hLS+P9998nICCALVu28Oyzz7Jhw4bc49PS0mjbti1//PEHgYGBfPHFF6xevZqIiAi8vLyYO3cuERERxMbGsm3bNrZu3cqoUaMAeO2119i0aRNbtmxhxowZZ8X20EMPcdddd7FlyxaGDx/+t+q1Q4cOsWrVKhYtWsSkSZPOOvb06dNERUXRqFEjwI4f+Oabb9i4cSPLly9n4sSJGMdyw7t27eKuu+5i06ZN7Nq1iz179rBu3ToiIiLYsGEDK1asAGDWrFls2LCB8PBwpk6dytECFhabMGFCblVQ3p+CqtNiY2OpX/+v9XGCg4OJjY09a7/du3ezcuVKunXrRu/evVm/fn3utn379tGhQwd69+7NypUrc18PCAggIyOjwBiLWqktUfyx7yiNAisT5Ffx0k40fjy8+65tpP7pJ11IqBS5mG/+rpCUlMSJEyfo3bs3ACNGjODmm2/mxIkTpKSkcNlllwEwbNgwFi1adNbx//jHP3j00UcZPnw4Q4cOJTi48BmQly5dyrx583KfBwQEFLjf8OHDSUtLIzs7m42OJXd/+uknFixYwJQpUwDb3fjgwYOsWrUqt1TTtm1bQkNDc8/j5eWVW2L55Zdf2LBhA126dAFsG0FQUBCDBg0iKiqKcePGce211zJgwAAAQkNDGT58OEOGDMlNVnmtWbOGr7/+GoA777wzt24e7Lf7cuXK0bp1a44cOXLWsYmJiVSrVi33uTGGp556ihUrVlCuXDliY2Nzj2vYsCHdu3fP/Qx++uknOnToANiSyJ49e7j88suZOnUq33zzDQDR0dHs2bOHwMC/TzT69ttvF/h5F+RMosqroF5JWVlZHD9+nLVr17J+/XpuueUWoqKiqFOnDgcPHiQwMJANGzYwZMgQtm/fjp+fnYUiKCiIuLi4s2IsaqUyUWRm57A26hjXt7/IuZ1ycsAYO+V3167w3HN2rYiKl5h0lMqjoJtEQSZNmsS1117LDz/8QPfu3Vm6dOl5z+tMF8i5c+cSFhbGpEmTGDt2LF9//TXGGL766itatmzpdKwVK1bMLQ0ZYxgxYgSvvvrqWftt3ryZJUuWMH36dObPn8+sWbP4/vvvWbFiBQsWLODll19m+/bthcac932dqYY5V3yVKlX623iBuXPnkpCQwIYNGyhfvjyNGjXK3V6lSpW/nevJJ5/k/vvv/9v5fv31V5YuXcqaNWuoXLkyffr0KXA8woQJE1i+fPlZr992221nlXyCg4OJjo7OfR4TE0Pdumfft4KDgxk6dCgiQteuXSlXrhyJiYnUrFkz93Po1KkTTZs2Zffu3XR2rGmTnp5OpUqVzjpfUSuVVU87DiWTmpHFZU0vIotu3mwn7Zs+3T4fNgxefFGThLpo/v7+BAQE5FYLfPLJJ/Tu3ZuAgAB8fX1Zu3YtwN9KAXn9+eeftGvXjieeeILOnTuzc+dOfH19SUlJKXD/AQMGMG3atNznhfV8KV++PJMnT2bt2rXs2LGDq666ivfeey/3xrtp0yYAevbsyfz58wGIjIxk69atBZ7viiuu4MsvvyQ+Ph6AY8eOceDAARITE8nJyeHGG2/k5ZdfZuPGjeTk5BAdHU3fvn154403OHHiBKmpqX8732WXXZb7ucydO5eeFzCANSAggOzs7NybeVJSEkFBQZQvX57ly5dz4MCBAo+76qqrmDVrVm4ssbGxxMfHk5SUREBAAJUrV2bnzp25v7f83n77bSIiIs76Kah67Prrr2fevHlkZGSwb98+9uzZQ9euXc/ab8iQISxbtgyw1VCnT5+mRo0aJCQk5PboioqKYs+ePTRxzCVnjOHw4cO5VW+uVCpLFJsOngCgQ4OCi9wFSk2F55+31UzVq0Pt2i6KTnm6kydP/q166NFHH+X//u//chuzmzRpwuzZswH4+OOPuffee6lSpQp9+vTB39//rPO98847LF++HC8vL1q3bs3VV19NuXLl8Pb2JiwsjJEjR+ZWkwA888wzjB07lrZt2+Ll5cXzzz/P0KFDzxlvpUqVmDhxIlOmTGHatGmMHz+e0NBQjDE0atSIRYsW8eCDtpG8YgAAC1NJREFUDzJixAhCQ0Pp0KEDoaGhBcbaunVrJk+ezIABA8jJyaF8+fJMnz6dSpUqMWrUKHJycgDbJTQ7O5s77riDpKQkjDFMmDDhb1VFAFOnTmX06NG8+eabuY3ZF2LAgAGsWrWK/v37M3z4cAYNGkTnzp1p3749ISEh5zxmx44duQ3KVatW5dNPP2XgwIHMmDGD0NBQWrZsmVtVdSnatGnDLbfcQuvWrfH29mb69Om5pbN77rmHMWPG0LlzZ0aPHs3o0aNp27YtPj4+/N///V9ux4bnnnsOb29vvLy8mDFjBtWr23bZDRs20L17d7y9i+E2frHdpdz106lTJ/PI5xtNl8k/m5ycnAK7hp3l55+NCQ42Boy57z5jjh1z7jhV4pSE7rEXIiUlJffxq6++ah5++GE3RnNuWVlZ5tSpU8YYY/bu3WsaNmxoMjIy3BzV+W3cuNHccccd7g7DLR5++GGzdOnSArdp91hgw8HjdGhQzfmh6j4+thTxxRe22kmpYvL999/z6quvkpWVRcOGDZkzZ467QyrQyZMn6du3L5mZmRhj+OCDD/DxKSFrzxeiQ4cO9O3bl+zs7HP2KvNUbdu25f/bu/tgqeo6juPvT3gvF3k0MMZAxAwUJhGBzCJIgwhpJnO0IaMcnGboSaopGmbQoRki08AxGccxJAYLhUZAMsvHki4jIA9yhas3GJKka5aIQiEUT9/++P3W3bns3T0sdx/5vmZ2ds/u75zz3e+9e37n8XvGjRtXknnJEh5wqxTDR4y0/RPmMGvSJUwbe1H2RkePhtuPHjgAc+eG906cgPdV5SEZl6GlpYUhQ4aUOwznKlq234mkLWY2qpDpVd2S8/CRcGDnI/1O3n8KwLp1MHJkuJFQS0voIMA7iRpSbSs3zpVSMX4fVbf0PHy0nY7i7bdh2jQYPRr274fVq2HlSu8gakxDQwP79u3zzsK5LMzC/SgaOvgszqo7RnH4yDGGnduVHg1tSnzv2wcPPwwzZoSzmzqgcJurPP3796e1tZW9e/eWOxTnKlLqDncdqeo6ikNHjnNZ/3iK3Y4d4QD17NkwaBC89hoU+QpFV151dXUdeucu51x+Rd0vI2mipB2Sdkk66WoUBQvi59skjcg3zWMnjEt714fOYdgwuPtuSF356J2Ec851uKKd9SSpE7AT+AzQCmwCbjSzVzLaTAKmA5OAjwH3mFnOiny939/PXu/emYY9u2HKFLjrLuhb5DvcOedclavUs56uAHaZ2atmdgRYDlzbps21wK/i9SAbgF6Szss10fMP/Iv6+k7w7LOwdKl3Es45V2TFPEbRD/h7xnArYashX5t+wBuZjSRNA1KF4f/XadeuZsaP79hoq1Mf4K1yB1EhPBdpnos0z0XaxfmbZFfMjiLbZdNt93MlaYOZLQQWAkjaXOjmU63xXKR5LtI8F2meizRJmwsdt5i7nlqB8zOG+wP/KKCNc865MipmR7EJGCTpQkn1wJeAx9q0eQy4KZ79dCVwwMzeaDsh55xz5VO0XU9mdkzSLcBTQCdgsZm9LOkb8fP7gT8QznjaBRwCbk4w6YVFCrkaeS7SPBdpnos0z0VawbmouqKAzjnnSssLITnnnMvJOwrnnHM5VWxHUYzyH9UqQS6mxBxsk7RO0mXliLMU8uUio91HJR2XdEMp4yulJLmQdJWkJkkvS/pzqWMslQS/kZ6SfifppZiLJMdDq46kxZLelNTczueFLTcLvTVeMR+Eg99/BT4E1AMvAUPbtJkEPEG4FuNK4IVyx13GXHwCOCe+vuZMzkVGuz8RTpa4odxxl/H/ohfwCjAgDn+g3HGXMRezgDvj63OBt4H6csdehFyMBUYAze18XtBys1K3KIpS/qNK5c2Fma0zs3fi4AbC9Si1KMn/BYT6YSuBN0sZXIklycWXgVVmtgfAzGo1H0lyYUB3hfsndyN0FMdKG2bxmVkj4bu1p6DlZqV2FO2V9jjVNrXgVL/n1whrDLUoby4k9QOuA+4vYVzlkOT/YjBwjqQ1krZIuqlk0ZVWklzcCwwhXNC7HfiumZ0oTXgVpaDlZqXej6LDyn/UgMTfU9LVhI7ik0WNqHyS5OLnwEwzOx5WHmtWklycBYwExgFdgPWSNpjZzmIHV2JJcvFZoAn4NHAR8IyktWb272IHV2EKWm5Wakfh5T/SEn1PScOARcA1ZravRLGVWpJcjAKWx06iDzBJ0jEzW12aEEsm6W/kLTN7F3hXUiNwGaH8fy1JkoubgTss7KjfJWk3cAmwsTQhVoyClpuVuuvJy3+k5c2FpAHAKuCrNbi2mClvLszsQjMbaGYDgRXAt2qwk4Bkv5HfAmMknSXpbEL15pYSx1kKSXKxh7BlhaS+hEqqr5Y0yspQ0HKzIrcorHjlP6pOwlzMBnoD98U16WNWgxUzE+bijJAkF2bWIulJYBtwAlhkZllPm6xmCf8vfgwskbSdsPtlppnVXPlxScuAq4A+klqBHwF1cHrLTS/h4ZxzLqdK3fXknHOuQnhH4ZxzLifvKJxzzuXkHYVzzrmcvKNwzjmXk3cUriLFyq9NGY+BOdoe7ID5LZG0O87rRUkfL2AaiyQNja9ntfls3enGGKeTyktzrIbaK0/74ZImdcS83ZnLT491FUnSQTPr1tFtc0xjCfC4ma2QNAGYb2bDTmN6px1TvulKehDYaWY/ydF+KjDKzG7p6FjcmcO3KFxVkNRN0h/j2v52SSdVjZV0nqTGjDXuMfH9CZLWx3EfkZRvAd4IfDiO+/04rWZJ34vvdZX0+3hvg2ZJk+P7aySNknQH0CXG8VD87GB8/k3mGn7ckrleUidJ8yRtUrhPwNcTpGU9saCbpCsU7kWyNT5fHK9SngNMjrFMjrEvjvPZmi2Pzp2k3PXT/eGPbA/gOKGIWxPwKKGKQI/4WR/ClaWpLeKD8fkHwK3xdSege2zbCHSN788EZmeZ3xLivSuALwIvEArqbQe6EkpTvwxcDlwPPJAxbs/4vIaw9v5eTBltUjFeBzwYX9cTKnl2AaYBt8X3OwObgQuzxHkw4/s9AkyMwz2As+Lr8cDK+HoqcG/G+LcDX4mvexHqPnUt99/bH5X9qMgSHs4Bh81seGpAUh1wu6SxhHIU/YC+wD8zxtkELI5tV5tZk6RPAUOB52N5k3rCmng28yTdBuwlVOEdBzxqoageklYBY4AngfmS7iTsrlp7Ct/rCWCBpM7ARKDRzA7H3V3DlL4jX09gELC7zfhdJDUBA4EtwDMZ7R+UNIhQDbSunflPAD4vaUYcbgAGUJs1oFwH8Y7CVYsphDuTjTSzo5L+RljIvcfMGmNH8jng15LmAe8Az5jZjQnm8UMzW5EakDQ+WyMz2ylpJKFmzk8lPW1mc5J8CTP7r6Q1hLLXk4FlqdkB083sqTyTOGxmwyX1BB4Hvg0sINQyes7MrosH/te0M76A681sR5J4nQM/RuGqR0/gzdhJXA1c0LaBpAtimweAXxJuCbkBGC0pdczhbEmDE86zEfhCHKcrYbfRWkkfBA6Z2VJgfpxPW0fjlk02ywnF2MYQCtkRn7+ZGkfS4DjPrMzsAPAdYEYcpyfwevx4akbT/xB2waU8BUxX3LySdHl783AuxTsKVy0eAkZJ2kzYuvhLljZXAU2SthKOI9xjZnsJC85lkrYROo5LkszQzF4kHLvYSDhmscjMtgKXAhvjLqBbgblZRl8IbEsdzG7jacK9jZ+1cOtOCPcSeQV4UVIz8AvybPHHWF4ilNX+GWHr5nnC8YuU54ChqYPZhC2Puhhbcxx2Lic/PdY551xOvkXhnHMuJ+8onHPO5eQdhXPOuZy8o3DOOZeTdxTOOedy8o7COedcTt5ROOecy+n/5A7rzH8GoJMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "logit_roc_auc = roc_auc_score(y_test, logreg.predict(X_test))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(X_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold value is: 0.38466641164306037\n"
     ]
    }
   ],
   "source": [
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "print(\"Threshold value is:\", optimal_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1028696, 429655, 26610, 54501)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "THRESHOLD = optimal_threshold\n",
    "preds = np.where(logreg.predict_proba(X_test)[:,1] > THRESHOLD, 1, 0)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.71      0.82   1458351\n",
      "           1       0.11      0.67      0.19     81111\n",
      "\n",
      "    accuracy                           0.70   1539462\n",
      "   macro avg       0.54      0.69      0.51   1539462\n",
      "weighted avg       0.93      0.70      0.79   1539462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we applied XGBoost to the full dataset. Ideally, we would want to tune the following parameters: \n",
    "1. *n_estimators*: number of estimators when boosting is terminated. \n",
    "2. *max_depth*: maximum depth of a tree. Higher value can make the tree overfit\n",
    "3. *gamma*: minimum loss reduction required to make partition on a leaf node of the tree. the higher value of gamma, the more conservative the algorithm will be\n",
    "\n",
    "However, since *GridSearchCV* performs exhaustive search over specified parameter values, it will take hours, if not days, for it to finish tuning our parameters given our laptop are not of the professionals. Therefore, in the interest of time, we will specify these parameters manually. Below is the codes for which we will use to tune our parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## XGB - number of estimators\n",
    "param_test = {'n_estimators': range(50, 500, 50)}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier(objective='binary:logistic', scale_pos_weight = 18, learning_rate=0.2, \n",
    "                                                  use_label_encoder =False, eval_metric = 'auc'), \n",
    "                        param_grid = param_test, scoring='roc_auc', n_jobs=-1, cv=5)\n",
    "gsearch1.fit(X_train, y_train)\n",
    "gsearch1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## XGB - maximum tree depth\n",
    "param_test2 = {'max_depth':range(1,10,2)}\n",
    "gsearch2 = GridSearchCV(estimator = XGBClassifier(objective='binary:logistic', scale_pos_weight = 18,\n",
    "                                                  n_estimators = gsearch1.best_params_['n_estimators'], \n",
    "                                                  learning_rate = 0.2, use_label_encoder =False, eval_metric = 'auc'), \n",
    "                        param_grid = param_test2, scoring='roc_auc', n_jobs=-1, cv=5)\n",
    "\n",
    "gsearch2.fit(X_train, y_train)\n",
    "gsearch2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tuning gamma parameter\n",
    "param_test3 = {'gamma': [i/10.0 for i in range(0,5)]} \n",
    "gsearch3 = GridSearchCV(estimator = XGBClassifier(objective='binary:logistic', scale_pos_weight = 18,\n",
    "                                                  n_estimators = gsearch1.best_params_['n_estimators'], \n",
    "                                                  learning_rate = 0.2, use_label_encoder =False, eval_metric = 'auc',\n",
    "                                                  max_depth = gsearch2.best_params_['max_depth']), \n",
    "                        param_grid = param_test3, scoring='roc_auc', n_jobs=-1, cv=5)\n",
    "\n",
    "gsearch3.fit(X_train, y_train)\n",
    "gsearch3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tuned model\n",
    "XGB_model = XGBClassifier(objective='binary:logistic', scale_pos_weight = 18, n_estimators = gsearch1.best_params_, \n",
    "                          max_depth = gsearch2.best_params_, gamma = gsearch3.best_params_, \n",
    "                          scale_pos_weight = 17, n_jobs=-1, learning_rate = 0.2, \n",
    "                          #we need to account for imbalance class ratio 1:17.98 using scale_pos_weight\n",
    "                          use_label_encoder =False, eval_metric = 'auc')\n",
    "\n",
    "XGB_model.fit(X_train, y_train)\n",
    "XGB_model_predict = XGB_model.predict(X_test)\n",
    "XGB_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will then specify the parameters manually: \n",
    "1. *n_estimators*: 50 as a value that would work well given the power of our system\n",
    "2. *max_depth*: as the default is 6 and increasing this value will make the model more complex and overfit, we will go with 7\n",
    "3. *gamma*: the default value is 0 and increasing it will make the algorithm more conservative. Thus, we want to start at a smaller value like 0.1 and can alter it later on if required\n",
    "4. *scale_pos_weight*: since the ratio between class 0 and 1 is 18, we will specify this value for this parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full dataset split\n",
    "X_train = train.drop(\"Buy\", axis=1)\n",
    "y_train = train[\"Buy\"]\n",
    "\n",
    "X_test = test.drop(\"Buy\", axis=1)\n",
    "y_test = test[\"Buy\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(alpha=0.1, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, eval_metric='auc',\n",
       "              gamma=0, gpu_id=-1, importance_type='gain',\n",
       "              interaction_constraints='', learning_rate=1, max_delta_step=0,\n",
       "              max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=50, n_jobs=-1,\n",
       "              num_parallel_tree=1, random_state=0, reg_alpha=0.100000001,\n",
       "              reg_lambda=1, scale_pos_weight=18, subsample=1,\n",
       "              tree_method='approx', use_label_encoder=False,\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Tuned model\n",
    "XGB_model = XGBClassifier(objective='binary:logistic', n_estimators = 50, \n",
    "                          scale_pos_weight = 18, n_jobs=-1, learning_rate = 1, alpha = 0.1,\n",
    "                          #we need to account for imbalance class ratio 1:17.98 using scale_pos_weight\n",
    "                          use_label_encoder =False, eval_metric = 'auc')\n",
    "\n",
    "XGB_model.fit(X_train, y_train)\n",
    "XGB_model_predict = XGB_model.predict(X_test)\n",
    "XGB_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Test Accuracy: 0.9217427906632317 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96   1458351\n",
      "           1       0.20      0.16      0.18     81111\n",
      "\n",
      "    accuracy                           0.92   1539462\n",
      "   macro avg       0.58      0.56      0.57   1539462\n",
      "weighted avg       0.91      0.92      0.92   1539462\n",
      "\n",
      "[[1405785   52566]\n",
      " [  67908   13203]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('XGB Test Accuracy:', accuracy_score(y_test, XGB_model_predict), '\\n')\n",
    "print(classification_report(y_test, XGB_model_predict))\n",
    "print(confusion_matrix(y_test, XGB_model_predict), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observing the results above, our parameters will need further tuning to be able to classify class 1 better. We chose to add a booster called 'gblinear', which uses linear functions instead of the default 'gbtree', which uses tree based model. We chose linear functions since logistic regression and SVM, which are both linear classifiers, seem to work well on this dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(alpha=0.1, base_score=0.5, booster='gblinear',\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, eval_metric='auc', gamma=None, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=1, max_delta_step=None, max_depth=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=50, n_jobs=-1, num_parallel_tree=None,\n",
       "              random_state=0, reg_alpha=0, reg_lambda=0, scale_pos_weight=18,\n",
       "              subsample=None, tree_method=None, use_label_encoder=False,\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Tuned model\n",
    "XGB_model = XGBClassifier(objective='binary:logistic', n_estimators = 50, booster = 'gblinear',\n",
    "                          scale_pos_weight = 18, n_jobs=-1, learning_rate = 1, alpha = 0.1,\n",
    "                          #we need to account for imbalance class ratio 1:17.98 using scale_pos_weight\n",
    "                          use_label_encoder =False, eval_metric = 'auc')\n",
    "\n",
    "XGB_model.fit(X_train, y_train)\n",
    "XGB_model_predict = XGB_model.predict(X_test)\n",
    "XGB_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Test Accuracy: 0.7437695766443082 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.75      0.85   1458351\n",
      "           1       0.13      0.64      0.21     81111\n",
      "\n",
      "    accuracy                           0.74   1539462\n",
      "   macro avg       0.55      0.70      0.53   1539462\n",
      "weighted avg       0.93      0.74      0.81   1539462\n",
      "\n",
      "[[1092744  365607]\n",
      " [  28850   52261]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('XGB Test Accuracy:', accuracy_score(y_test, XGB_model_predict), '\\n')\n",
    "print(classification_report(y_test, XGB_model_predict))\n",
    "print(confusion_matrix(y_test, XGB_model_predict), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we applied CatBoost to the full dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full dataset split\n",
    "X_train = train.drop(\"Buy\", axis=1)\n",
    "y_train = train[\"Buy\"]\n",
    "\n",
    "X_test = test.drop(\"Buy\", axis=1)\n",
    "y_test = test[\"Buy\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to our reasoning for XGBoost above, we will manually specify the parameters for this model:\n",
    "1. *iterations*: 50 as a good value for our computer performance\n",
    "2. *class_weights*: given the ratio between class 0 and 1 at 1:18, we will specify this in our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttotal: 862ms\tremaining: 42.3s\n",
      "1:\ttotal: 1.58s\tremaining: 37.8s\n",
      "2:\ttotal: 2.28s\tremaining: 35.7s\n",
      "3:\ttotal: 3s\tremaining: 34.4s\n",
      "4:\ttotal: 3.74s\tremaining: 33.7s\n",
      "5:\ttotal: 4.47s\tremaining: 32.8s\n",
      "6:\ttotal: 5.14s\tremaining: 31.6s\n",
      "7:\ttotal: 5.87s\tremaining: 30.8s\n",
      "8:\ttotal: 6.56s\tremaining: 29.9s\n",
      "9:\ttotal: 7.18s\tremaining: 28.7s\n",
      "10:\ttotal: 7.82s\tremaining: 27.7s\n",
      "11:\ttotal: 8.48s\tremaining: 26.9s\n",
      "12:\ttotal: 9.15s\tremaining: 26s\n",
      "13:\ttotal: 10.1s\tremaining: 25.9s\n",
      "14:\ttotal: 11.1s\tremaining: 25.9s\n",
      "15:\ttotal: 12.2s\tremaining: 25.8s\n",
      "16:\ttotal: 13.2s\tremaining: 25.6s\n",
      "17:\ttotal: 14s\tremaining: 24.9s\n",
      "18:\ttotal: 14.9s\tremaining: 24.3s\n",
      "19:\ttotal: 15.8s\tremaining: 23.6s\n",
      "20:\ttotal: 16.7s\tremaining: 23s\n",
      "21:\ttotal: 17.7s\tremaining: 22.5s\n",
      "22:\ttotal: 18.7s\tremaining: 21.9s\n",
      "23:\ttotal: 19.8s\tremaining: 21.5s\n",
      "24:\ttotal: 20.8s\tremaining: 20.8s\n",
      "25:\ttotal: 21.8s\tremaining: 20.1s\n",
      "26:\ttotal: 22.6s\tremaining: 19.2s\n",
      "27:\ttotal: 23.3s\tremaining: 18.3s\n",
      "28:\ttotal: 24.1s\tremaining: 17.5s\n",
      "29:\ttotal: 24.9s\tremaining: 16.6s\n",
      "30:\ttotal: 25.7s\tremaining: 15.7s\n",
      "31:\ttotal: 26.6s\tremaining: 14.9s\n",
      "32:\ttotal: 27.3s\tremaining: 14.1s\n",
      "33:\ttotal: 28.1s\tremaining: 13.2s\n",
      "34:\ttotal: 28.9s\tremaining: 12.4s\n",
      "35:\ttotal: 29.8s\tremaining: 11.6s\n",
      "36:\ttotal: 30.7s\tremaining: 10.8s\n",
      "37:\ttotal: 31.6s\tremaining: 9.99s\n",
      "38:\ttotal: 32.6s\tremaining: 9.21s\n",
      "39:\ttotal: 33.6s\tremaining: 8.39s\n",
      "40:\ttotal: 34.6s\tremaining: 7.59s\n",
      "41:\ttotal: 35.6s\tremaining: 6.78s\n",
      "42:\ttotal: 36.5s\tremaining: 5.94s\n",
      "43:\ttotal: 37.5s\tremaining: 5.12s\n",
      "44:\ttotal: 38.4s\tremaining: 4.27s\n",
      "45:\ttotal: 39.3s\tremaining: 3.42s\n",
      "46:\ttotal: 40s\tremaining: 2.55s\n",
      "47:\ttotal: 40.9s\tremaining: 1.71s\n",
      "48:\ttotal: 41.7s\tremaining: 851ms\n",
      "49:\ttotal: 42.4s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "ctb = CatBoostClassifier(eval_metric='AUC', learning_rate = 0.2, class_weights={0: 1, 1: 18}, iterations=50)\n",
    "ctb.fit(X_train, y_train)\n",
    "y_pred = ctb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nan_mode': 'Min', 'eval_metric': 'AUC', 'iterations': 50, 'sampling_frequency': 'PerTree', 'leaf_estimation_method': 'Newton', 'grow_policy': 'SymmetricTree', 'penalties_coefficient': 1, 'boosting_type': 'Plain', 'model_shrink_mode': 'Constant', 'feature_border_type': 'GreedyLogSum', 'bayesian_matrix_reg': 0.10000000149011612, 'l2_leaf_reg': 3, 'random_strength': 1, 'rsm': 1, 'boost_from_average': False, 'model_size_reg': 0.5, 'pool_metainfo_options': {'tags': {}}, 'subsample': 0.800000011920929, 'use_best_model': False, 'class_names': [0, 1], 'random_seed': 0, 'depth': 6, 'posterior_sampling': False, 'border_count': 254, 'class_weights': [1, 18], 'classes_count': 0, 'auto_class_weights': 'None', 'sparse_features_conflict_fraction': 0, 'leaf_estimation_backtracking': 'AnyImprovement', 'best_model_min_trees': 1, 'model_shrink_rate': 0, 'min_data_in_leaf': 1, 'loss_function': 'Logloss', 'learning_rate': 0.20000000298023224, 'score_function': 'Cosine', 'task_type': 'CPU', 'leaf_estimation_iterations': 1, 'bootstrap_type': 'MVS', 'max_leaves': 64}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97   1458351\n",
      "           1       0.28      0.00      0.00     81111\n",
      "\n",
      "    accuracy                           0.95   1539462\n",
      "   macro avg       0.61      0.50      0.49   1539462\n",
      "weighted avg       0.91      0.95      0.92   1539462\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(ctb.get_all_params())\n",
    "print(classification_report(y_test, y_pred), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1458309, 42, 81095, 16)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As observed above, CatBoost does not work well in the full dataset compare to its performance in the sample dataset. Additionally, it does not allow us to specify between tree based model and linear functions. Thus, we were unable to improve on its performance. This is one of the reasons why XGBoost is so popular given its flexibility in using both linear model and tree learning algorithms.\n",
    "\n",
    "As Light GBM is a similar method to CatBoost and XGBoost, while not having the flexibility as XGBoost in specifying the linear functions. It only allows to choosing tree-based methods, such as random forest, gradient boosting decision tree, etc, as boosting types. Thus, we decided to not run it on the full dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we apply SVM to our full dataset. Similar to our reasoning for XGBoost and CatBoost, we will manually specify the parameters for our model:\n",
    "1. *max_iter*: the default maximum number of passes over training data is 1000. However, in the interest of time and computer limitations, we will use 100 \n",
    "2. *loss*: we used hinge as it is a loss function typically used for training classifiers\n",
    "3. *penalty*: we used l1 as our regularisation term as it might bring sparsity in our model by shrinking some feature coefficients to 0, which helps reducing its complexity while still reducing the model's variance\n",
    "4. *class_weight*: even though our actual ratio is 1:18, after testing with a few weights, we found that 1:36 gives us better performance results. This means that we need to give twice the weight from the original ratio to class 1\n",
    "5. *alpha*: given that the default is 0.0001 and the higher the value, the stronger the regularisation, we chose alpha value at 0.01 so that it will penalises more when there is a misclassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.01, class_weight={0: 1, 1: 36}, max_iter=100, n_jobs=-1,\n",
       "              penalty='l1')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "SVM_Xtrain = scaler.fit_transform(X_train)\n",
    "SVM_Xtest = scaler.transform(X_test)\n",
    "clf = SGDClassifier(loss='hinge', penalty='l1', n_jobs=-1, class_weight={0: 1, 1: 36}, max_iter=100,\n",
    "                   alpha=0.01)\n",
    "clf.fit(SVM_Xtrain, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.76      0.85   1458351\n",
      "           1       0.13      0.64      0.21     81111\n",
      "\n",
      "    accuracy                           0.75   1539462\n",
      "   macro avg       0.55      0.70      0.53   1539462\n",
      "weighted avg       0.93      0.75      0.82   1539462\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1103971, 354380, 29588, 51523)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(SVM_Xtest)\n",
    "print(classification_report(y_test, y_pred))\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As observed above, when implementing the models to the full dataset, the performance between each varies significantly. CatBoost does terrible, while Logistic Regression, XGBoost and SVM do much better. As Logistic Regression and XGBoost have slightly better performance than SVM, we will implement these two methods in our final results and compare the scoring. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Data - Model Performance Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have a large dataset, we will compare model performance based on a small subset of data. In this case, we will use latest month data to run our models, make predictions, and compare performances. In this case, we will split the test_data, which also is latest 1-month data, into training set and testing set using 75:25 ratio. \n",
    "\n",
    "Here, we also observed the highly imbalanced ratio between class 0 and class 1, which helps when training the models as it mimics the issue we have observed in the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d7b4919e80>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAERCAYAAAB2CKBkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAQfUlEQVR4nO3da4ycV33H8e8PO+EioKF4acGOaxcZIosmFJZAkVoCUYoTibogShMugTSpG4kg9QUoUVWRqlGlIqhEaRIsizpWEE0EJaQBGfKiF4KaRHhdQrCNTK2kxIvTenMBCrSkG/59MWOYrGfXY7PPjtfn+5FGnuecM8/+La3mt+e5nCdVhSSpXU8bdwGSpPEyCCSpcQaBJDXOIJCkxhkEktQ4g0CSGrcsgyDJ9iSHk+wZcfzbkuxLsjfJ33VdnyQtJ1mO9xEk+S3gB8DNVfWyY4zdAHwaeENVPZ7kBVV1eCnqlKTlYFnOCKrqLuCxwbYkL07ypSS7k3wlyVn9rj8Ebqiqx/ufNQQkacCyDIJ5bAPeV1WvBN4P3NhvfwnwkiT/muTeJJvGVqEknYRWjruAxZDk2cBrgc8kOdL89P6/K4ENwHnAGuArSV5WVd9d6jol6WR0SgQBvZnNd6vq5UP6poF7q+r/gAeT7KcXDLuWskBJOlmdEoeGqur79L7kfw8gPef0u28HXt9vX0XvUNEDYylUkk5CyzIIktwC3AO8NMl0ksuBdwCXJ/k6sBfY3B9+J/Bokn3APwMfqKpHx1G3JJ2MluXlo5KkxbMsZwSSpMWz7E4Wr1q1qtatWzfuMiRpWdm9e/cjVTUxrG/ZBcG6deuYmpoadxmStKwk+fZ8fR4akqTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxi27O4sXwys/cPO4S9BJaPeHLx13CdJYOCOQpMYZBJLUOINAkhpnEEhS4zoLgiTbkxxOsucY416V5Mkkb+2qFknS/LqcEewANi00IMkK4EP0nissSRqDzoKgqu4CHjvGsPcBnwUOd1WHJGlhYztHkGQ18GZg6whjtySZSjI1MzPTfXGS1JBxniz+KHB1VT15rIFVta2qJqtqcmJi6CM3JUknaJx3Fk8CtyYBWAVclGS2qm4fY02S1JyxBUFVrT/yPskO4AuGgCQtvc6CIMktwHnAqiTTwLXAaQBVdczzApKkpdFZEFTVJccx9j1d1SFJWph3FktS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmN6ywIkmxPcjjJnnn635Hk/v7r7iTndFWLJGl+Xc4IdgCbFuh/EHhdVZ0NXAds67AWSdI8Vna146q6K8m6BfrvHti8F1jTVS2SpPmdLOcILge+OF9nki1JppJMzczMLGFZknTqG3sQJHk9vSC4er4xVbWtqiaranJiYmLpipOkBnR2aGgUSc4GPgFcWFWPjrMWSWrV2GYESdYCtwHvqqpvjasOSWpdZzOCJLcA5wGrkkwD1wKnAVTVVuCDwPOBG5MAzFbVZFf1SJKG6/KqoUuO0X8FcEVXP1+SNJqxnyyWJI2XQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1rrMgSLI9yeEke+bpT5KPJTmQ5P4kr+iqFknS/LqcEewANi3QfyGwof/aAny8w1okSfPoLAiq6i7gsQWGbAZurp57gTOSvLCreiRJw43zHMFq4ODA9nS/7ShJtiSZSjI1MzOzJMVJUivGGQQZ0lbDBlbVtqqarKrJiYmJjsuSpLaMMwimgTMHttcAh8ZUiyQ1a5xBcAdwaf/qodcA36uqh8dYjyQ1aWVXO05yC3AesCrJNHAtcBpAVW0FdgIXAQeAHwGXdVWLJGl+nQVBVV1yjP4C3tvVz5ckjcY7iyWpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjRspCJL84yhtkqTlZ8EnlCV5BvAseo+bfB6QftdzgRd1XJskaQkc61GVfwT8Mb0v/d38LAi+D9zQYV2SpCWy4KGhqvrrqloPvL+qfrWq1vdf51TV9cfaeZJNSfYnOZDkmiH9v5Dk80m+nmRvEh9gL0lLbKSH11fV3yR5LbBu8DNVdfN8n0mygt6s4QJgGtiV5I6q2jcw7L3Avqp6U5IJYH+ST1XVE8f/X5EknYiRgiDJJ4EXA/cBT/abC5g3CIBzgQNV9UB/H7cCm4HBICjgOUkCPBt4DJg9nv+AJOnnM1IQAJPAxqqq49j3auDgwPY08Oo5Y64H7gAOAc8Bfr+qfjJ3R0m2AFsA1q5dexwlSJKOZdT7CPYAv3yc+86QtrlB8kZ6s4wXAS8Hrk/y3KM+VLWtqiaranJiYuI4y5AkLWTUGcEqYF+SrwI/PtJYVb+zwGemgTMHttfQ+8t/0GXAX/ZnGgeSPAicBXx1xLokST+nUYPgz05g37uADUnWA98BLgbePmfMQ8D5wFeS/BLwUuCBE/hZkqQTNOpVQ18+3h1X1WySq4A7gRXA9qram+TKfv9W4DpgR5Jv0DuUdHVVPXK8P0uSdOJGvWrov/nZ8f3TgdOAH1bVUcfzB1XVTmDnnLatA+8PAb99PAVLkhbXqDOC5wxuJ/ldepeHSpKWuRNafbSqbgfesMi1SJLGYNRDQ28Z2HwavfsKjueeAknSSWrUq4beNPB+FvgPencJS5KWuVHPEbgYnCSdokZ9MM2aJJ9LcjjJfyX5bJI1XRcnSereqCeLb6K3JtCL6K0h9Pl+myRpmRs1CCaq6qaqmu2/dgAu+iNJp4BRg+CRJO9MsqL/eifwaJeFSZKWxqhB8AfA24D/BB4G3kpvwThJ0jI36uWj1wHvrqrHAZL8IvARegEhSVrGRp0RnH0kBACq6jHg17spSZK0lEYNgqcled6Rjf6MYNTZhCTpJDbql/lfAXcn+Xt6S0u8DfiLzqqSJC2ZUe8svjnJFL2F5gK8par2HeNjkqRlYOTDO/0vfr/8JekUc0LLUEuSTh0GgSQ1ziCQpMZ1GgRJNiXZn+RAkmvmGXNekvuS7E3y5S7rkSQdrbN7AZKsAG4ALgCmgV1J7hi82ijJGcCNwKaqeijJC7qqR5I0XJczgnOBA1X1QFU9AdzK0U81eztwW1U9BFBVhzusR5I0RJdBsBo4OLA93W8b9BLgeUn+JcnuJJd2WI8kaYgul4nIkLa5D7xfCbwSOB94JnBPknur6ltP2VGyBdgCsHbt2g5KlaR2dTkjmAbOHNheAxwaMuZLVfXDqnoEuAs4Z+6OqmpbVU1W1eTEhM/DkaTF1GUQ7AI2JFmf5HTgYnqPuxz0D8BvJlmZ5FnAq4FvdliTJGmOzg4NVdVskquAO4EVwPaq2pvkyn7/1qr6ZpIvAfcDPwE+UVV7uqpJknS0TpeSrqqdwM45bVvnbH8Y+HCXdUiS5uedxZLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJalynQZBkU5L9SQ4kuWaBca9K8mSSt3ZZjyTpaJ0FQZIVwA3AhcBG4JIkG+cZ9yHgzq5qkSTNr8sZwbnAgap6oKqeAG4FNg8Z9z7gs8DhDmuRJM2jyyBYDRwc2J7ut/1UktXAm4GtC+0oyZYkU0mmZmZmFr1QSWpZl0GQIW01Z/ujwNVV9eRCO6qqbVU1WVWTExMTi1agJAlWdrjvaeDMge01wKE5YyaBW5MArAIuSjJbVbd3WJckaUCXQbAL2JBkPfAd4GLg7YMDqmr9kfdJdgBfMAQkaWl1FgRVNZvkKnpXA60AtlfV3iRX9vsXPC8gSVoaXc4IqKqdwM45bUMDoKre02UtkqThvLNYkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJalynQZBkU5L9SQ4kuWZI/zuS3N9/3Z3knC7rkSQdrbMgSLICuAG4ENgIXJJk45xhDwKvq6qzgeuAbV3VI0karssZwbnAgap6oKqeAG4FNg8OqKq7q+rx/ua9wJoO65EkDdFlEKwGDg5sT/fb5nM58MVhHUm2JJlKMjUzM7OIJUqSugyCDGmroQOT19MLgquH9VfVtqqarKrJiYmJRSxRkrSyw31PA2cObK8BDs0dlORs4BPAhVX1aIf1SJKG6HJGsAvYkGR9ktOBi4E7BgckWQvcBryrqr7VYS2SpHl0NiOoqtkkVwF3AiuA7VW1N8mV/f6twAeB5wM3JgGYrarJrmqSJB2ty0NDVNVOYOectq0D768AruiyBknSwryzWJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJalynaw1JOj4P/fmvjbsEnYTWfvAbne7fGYEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcZ0GQZJNSfYnOZDkmiH9SfKxfv/9SV7RZT2SpKN1FgRJVgA3ABcCG4FLkmycM+xCYEP/tQX4eFf1SJKG63JGcC5woKoeqKongFuBzXPGbAZurp57gTOSvLDDmiRJc3S51tBq4ODA9jTw6hHGrAYeHhyUZAu9GQPAD5LsX9xSm7YKeGTcRZwM8pF3j7sEPZW/m0dcm8XYy6/M19FlEAyrvE5gDFW1Ddi2GEXpqZJMVdXkuOuQ5vJ3c+l0eWhoGjhzYHsNcOgExkiSOtRlEOwCNiRZn+R04GLgjjlj7gAu7V899Brge1X18NwdSZK609mhoaqaTXIVcCewAtheVXuTXNnv3wrsBC4CDgA/Ai7rqh7Ny0NuOln5u7lEUnXUIXlJUkO8s1iSGmcQSFLjDIJGHWv5D2lckmxPcjjJnnHX0gqDoEEjLv8hjcsOYNO4i2iJQdCmUZb/kMaiqu4CHht3HS0xCNo039IekhpkELRppKU9JLXBIGiTS3tI+imDoE2jLP8hqREGQYOqahY4svzHN4FPV9Xe8VYl9SS5BbgHeGmS6SSXj7umU51LTEhS45wRSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQRpTkyST3Jfl6kn9L8tpx1yQtBi8flUaU5AdV9ez++zcCf1JVrxtzWdLPzRmBdGKeCzwOkOS8JF840pHk+iTvSXJ+ks8NtF+Q5LYx1CotqLOH10unoGcmuQ94BvBC4A3HGP9PwA1JJqpqBrgMuKnjGqXj5oxAGt3/VNXLq+oseg9OuTnJsJVcAajecddPAu9McgbwG8AXl6ZUaXTOCKQTUFX3JFkFTACzPPWPqmcMvL8J+Dzwv8Bn+us8SScVZwTSCUhyFrACeBT4NrAxydOT/AJw/pFxVXWI3hLff0rvEYzSSccZgTS6I+cIoPdwn3dX1ZPAwSSfBu4H/h342pzPfQqYqKp9S1eqNDovH5U6luR64GtV9bfjrkUaxiCQOpRkN/BD4IKq+vG465GGMQgkqXGeLJakxhkEktQ4g0CSGmcQSFLjDAJJatz/AyNgJG23VjeAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x = 'Buy', data=test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression is a discriminative classifier that uses a linear regression model to represent the probability through a logistic function in matrix notation: \n",
    "\\begin{equation}\n",
    "p(X) = \\frac{exp(w^Tx)}{1+exp(w^Tx)}\n",
    "\\end{equation}\n",
    "where $w^T$ represents the matrix for coefficients for each feature and x represents the observations. \n",
    "\n",
    "Logistic regression is popular machine learning method for binary classification. While simple, it gives good accuracy and has low training time. Additionally, it outputs a probability of the event being classified as class 0 or 1, which can then be adjusted using different threshold values depending on our classification purpose. For example, if the cost of misclassifying class 1 is too high, we would want to have a higher recall rate for class 1, thus we can do so by increasing the threshold value for the model to classify obsevation as class 1.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting data into training and test set\n",
    "X = test.drop(\"Buy\", axis=1)\n",
    "y = test[\"Buy\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While there are many features selection method, we use Recursive Feature Elimination method, which selects the most significant features by recursively considering smaller sets of features. The least important features are pruned from the current set of features and this process is repeated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lilyn199/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass n_features_to_select=20 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lilyn199/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "rfe = RFE(logreg, 20)\n",
    "rfe = rfe.fit(X_train, y_train.values.ravel())\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results above, all features are considered important so we will not need to remove any of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lilyn199/opt/anaconda3/lib/python3.8/site-packages/statsmodels/discrete/discrete_model.py:1747: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-X))\n",
      "/Users/lilyn199/opt/anaconda3/lib/python3.8/site-packages/statsmodels/discrete/discrete_model.py:1800: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(np.log(self.cdf(q*np.dot(X,params))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: inf\n",
      "         Iterations 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lilyn199/opt/anaconda3/lib/python3.8/site-packages/statsmodels/base/model.py:547: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  warn('Inverting hessian failed, no bse or cov_params '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Results: Logit\n",
      "======================================================================\n",
      "Model:                 Logit               Pseudo R-squared:    inf   \n",
      "Dependent Variable:    Buy                 AIC:                 inf   \n",
      "Date:                  2021-06-09 17:42    BIC:                 inf   \n",
      "No. Observations:      1154596             Log-Likelihood:      -inf  \n",
      "Df Model:              13                  LL-Null:             0.0000\n",
      "Df Residuals:          1154582             LLR p-value:         1.0000\n",
      "Converged:             1.0000              Scale:               1.0000\n",
      "No. Iterations:        9.0000                                         \n",
      "----------------------------------------------------------------------\n",
      "                     Coef.  Std.Err.     z     P>|z|   [0.025   0.975]\n",
      "----------------------------------------------------------------------\n",
      "num_clicks_session  -0.0170   0.0035   -4.8243 0.0000  -0.0238 -0.0101\n",
      "session_length       0.0000   0.0000    3.2503 0.0012   0.0000  0.0001\n",
      "Avg_time_bet_clicks  0.0002   0.0000   12.2732 0.0000   0.0002  0.0003\n",
      "Max_time_bet_clicks  0.0002   0.0000   12.4350 0.0000   0.0002  0.0002\n",
      "unique_items         0.1233   0.0040   30.9088 0.0000   0.1154  0.1311\n",
      "max_click_per_item   0.4071   0.0063   64.2447 0.0000   0.3947  0.4195\n",
      "max_hour            -0.0120   0.0009  -14.0244 0.0000  -0.0137 -0.0104\n",
      "max_day              0.0595   0.0019   30.8611 0.0000   0.0558  0.0633\n",
      "max_month           -0.4238   0.0021 -204.7445 0.0000  -0.4278 -0.4197\n",
      "Avg_item_price       0.0000   0.0000    2.5037 0.0123   0.0000  0.0001\n",
      "Popularity          -3.0173   8.4950   -0.3552 0.7224 -19.6671 13.6325\n",
      "perc_prod_offer     -0.0625   0.0109   -5.7365 0.0000  -0.0839 -0.0412\n",
      "perc_prod_no_cat    -0.1553   0.0303   -5.1220 0.0000  -0.2147 -0.0959\n",
      "perc_prod_pop       -1.6051   0.0219  -73.2333 0.0000  -1.6480 -1.5621\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lilyn199/opt/anaconda3/lib/python3.8/site-packages/statsmodels/base/model.py:547: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  warn('Inverting hessian failed, no bse or cov_params '\n"
     ]
    }
   ],
   "source": [
    "logit_model = sm.Logit(y_train,X_train)\n",
    "result = logit_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As Popularity has p-value greater than 0.05, it is considered insignificant, so we will remove it from our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(\"Popularity\", axis=1)\n",
    "X_test= X_test.drop(\"Popularity\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then address the issue of class imbalance in our dataset using the Synthetic Minority Over-Sampling Technique (SMOTE), which creates synthetic samples from minor class instead of simply creating copies. It works by randomly chooses one of the K-nearest-neighbours and use it to create similar but randomly tweaked, new observations. \n",
    "\n",
    "There are different opinions over whether we should eliminate features before or after SMOTE. The argument given is that SMOTE can induce bias and it violates the independence assumption as it uses KNN technique, which implies that there are relationships between these features. In our case, we know that these features are somewhat related to each other as they are generated from the same dataset, we chose to apply RFE before SMOTE.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of oversampled data is  2187264\n",
      "Number of no default in oversampled data 1093632\n",
      "Number of default 1093632\n",
      "Proportion of no default data in oversampled data is  0.5\n",
      "Proportion of default data in oversampled data is  0.5\n"
     ]
    }
   ],
   "source": [
    "os = SMOTE(random_state = 42, n_jobs=-1)\n",
    "columns = X_train.columns\n",
    "\n",
    "os_data_X, os_data_y = os.fit_resample(X_train, y_train)\n",
    "os_data_X = pd.DataFrame(data = os_data_X,columns = columns)\n",
    "os_data_y = pd.DataFrame(data = os_data_y,columns = ['Buy'])\n",
    "\n",
    "print(\"length of oversampled data is \",len(os_data_X))\n",
    "print(\"Number of no default in oversampled data\",len(os_data_y[os_data_y['Buy'] == 0]))\n",
    "print(\"Number of default\",len(os_data_y[os_data_y['Buy'] == 1]))\n",
    "print(\"Proportion of no default data in oversampled data is \",len(os_data_y[os_data_y['Buy'] == 0])/len(os_data_X))\n",
    "print(\"Proportion of default data in oversampled data is \",len(os_data_y[os_data_y['Buy'] == 1])/len(os_data_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lilyn199/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/Users/lilyn199/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(os_data_X, os_data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To analyse the Logistic Regression model performance, we will use the Receiver Operating Characteristic (ROC) Curve to find the optimal threshold as we look to have high recall rates for both class 0 and 1.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Create ROC curve\n",
    "logit_roc_auc = roc_auc_score(y_test, logreg.predict(X_test))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(X_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold value is: 0.4225121912160114\n"
     ]
    }
   ],
   "source": [
    "#Find optimal threshold\n",
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "print(\"Threshold value is:\", optimal_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(259153, 105566, 6650, 13497)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#results based on optimal threshold\n",
    "THRESHOLD = optimal_threshold\n",
    "preds = np.where(logreg.predict_proba(X_test)[:,1] > THRESHOLD, 1, 0)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.71      0.82    364719\n",
      "           1       0.11      0.67      0.19     20147\n",
      "\n",
      "    accuracy                           0.71    384866\n",
      "   macro avg       0.54      0.69      0.51    384866\n",
      "weighted avg       0.93      0.71      0.79    384866\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we also tried to optimise the Logistic Regression model by C or regularisation parameter, and penalty term, to see if we can further improve on the results. The larger the value of C, the higher the tolerance for misclassification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lilyn199/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:922: UserWarning: One or more of the test scores are non-finite: [0.74828288 0.74828267        nan 0.74828254 0.74828287 0.74828255\n",
      "        nan 0.74828292 0.74828287 0.74828266        nan 0.74828292\n",
      " 0.74828302 0.74828283        nan 0.74828299 0.74828273 0.74828264\n",
      "        nan 0.74828274 0.74828297 0.74828272        nan 0.74828281]\n",
      "  warnings.warn(\n",
      "/Users/lilyn199/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/Users/lilyn199/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100, solver='saga')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    \"C\": [0.1, 1, 10, 100, 500, 1000],\n",
    "    \"penalty\": [\"l2\", \"l1\", \"elasticnet\", \"none\"]\n",
    "}\n",
    "model = LogisticRegression(solver ='saga') #saga supports all penalty and faster for large dataset\n",
    "logreg = GridSearchCV(model, param_grid=params, n_jobs=-1, cv=5, scoring='roc_auc', refit=True)\n",
    "logreg.fit(os_data_X, os_data_y)\n",
    "logreg.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Create ROC curve\n",
    "logit_roc_auc = roc_auc_score(y_test, logreg.predict(X_test))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(X_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold value is: 0.5008915719078164\n"
     ]
    }
   ],
   "source": [
    "#find optimal threshold\n",
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "print(\"Threshold value is:\", optimal_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(266359, 98360, 6895, 13252)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#results based on optimal threshold\n",
    "THRESHOLD = optimal_threshold\n",
    "preds = np.where(logreg.predict_proba(X_test)[:,1] > THRESHOLD, 1, 0)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.73      0.84    364719\n",
      "           1       0.12      0.66      0.20     20147\n",
      "\n",
      "    accuracy                           0.73    384866\n",
      "   macro avg       0.55      0.69      0.52    384866\n",
      "weighted avg       0.93      0.73      0.80    384866\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As observed above, the results from our parameters tuning are similar to if we just use the default parameters. Hence, this might not be needed when running on the full dataset given the time it took to tune these parameters on large dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we tried a gradiant boosting machine learning method called XGBoost (extreme Gradient Boosting), which is an implementation of gradiant boosted decision trees. Boosting is an ensemble method, where models are added consecutively to improve accuracy of the previous ones, and gradient boosting uses gradient descent algorithm to minimise the loss when adding new models. \n",
    "\n",
    "XGBoost is popular as it provides results with high accuracy in both classification and regression problems. Before implementing XGBoost, we will tune 4 of its parameters:\n",
    "1. *n_estimators*: number of estimators when boosting is terminated. \n",
    "2. *max_depth*: maximum depth of a tree. Higher value can make the tree overfit\n",
    "3. *gamma*: minimum loss reduction required to make partition on a leaf node of the tree. the higher value of gamma, the more conservative the algorithm will be\n",
    "\n",
    "To tune these parameters, we will use *GridSearchCV()* which performs exhaustive search over specified parameter values for a model. It works by cross-validating grid-search over parameter grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting data into training and test set\n",
    "X = test.drop(\"Buy\", axis=1)\n",
    "y = test[\"Buy\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 53}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## XGB - number of estimators\n",
    "param_test = {'n_estimators': range(1,100,4)}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier(objective='binary:logistic', learning_rate=0.2, scale_pos_weight = 18,\n",
    "                                                  use_label_encoder =False, eval_metric = 'auc'), \n",
    "                        param_grid = param_test, scoring='roc_auc', n_jobs=-1, cv=5)\n",
    "gsearch1.fit(X_train, y_train)\n",
    "gsearch1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## XGB - maximum tree depth\n",
    "param_test2 = {'max_depth':range(1,10,2)}\n",
    "gsearch2 = GridSearchCV(estimator = XGBClassifier(objective='binary:logistic', scale_pos_weight = 18,\n",
    "                                                  n_estimators = gsearch1.best_params_['n_estimators'], \n",
    "                                                  learning_rate = 0.2, use_label_encoder =False, eval_metric = 'auc'), \n",
    "                        param_grid = param_test2, scoring='roc_auc', n_jobs=-1, cv=5)\n",
    "\n",
    "gsearch2.fit(X_train, y_train)\n",
    "gsearch2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gamma': 0.0}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tuning gamma parameter\n",
    "param_test3 = {'gamma': [i/10.0 for i in range(0,5)]} \n",
    "gsearch3 = GridSearchCV(estimator = XGBClassifier(objective='binary:logistic', scale_pos_weight = 18,\n",
    "                                                  n_estimators = gsearch1.best_params_['n_estimators'], \n",
    "                                                  learning_rate = 0.2, use_label_encoder =False, eval_metric = 'auc',\n",
    "                                                  max_depth = gsearch2.best_params_['max_depth']), \n",
    "                        param_grid = param_test3, scoring='roc_auc', n_jobs=-1, cv=5)\n",
    "\n",
    "gsearch3.fit(X_train, y_train)\n",
    "gsearch3.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our final model, we will also specify the scale_post_weight value, which is the ratio between class 0 and 1 at 18."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, eval_metric='auc',\n",
       "              gamma=0.0, gpu_id=-1, importance_type='gain',\n",
       "              interaction_constraints='', learning_rate=0.2, max_delta_step=0,\n",
       "              max_depth=5, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=85, n_jobs=-1,\n",
       "              num_parallel_tree=1, random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "              scale_pos_weight=17.98, subsample=1, tree_method='exact',\n",
       "              use_label_encoder=False, validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Tuned model\n",
    "XGB_model = XGBClassifier(objective='binary:logistic', n_estimators = gsearch1.best_params_['n_estimators'], \n",
    "                          max_depth = gsearch2.best_params_['max_depth'],gamma = gsearch3.best_params_['gamma'], \n",
    "                          scale_pos_weight = 18, n_jobs=-1, learning_rate = 0.2, \n",
    "                          #we need to account for imbalance class ratio 1:17.98 using scale_pos_weight\n",
    "                          use_label_encoder =False, eval_metric = 'auc')\n",
    "\n",
    "XGB_model.fit(X_train, y_train)\n",
    "XGB_model_predict = XGB_model.predict(X_test)\n",
    "XGB_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Test Accuracy: 0.740161510759589 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.74      0.84    364719\n",
      "           1       0.13      0.72      0.22     20147\n",
      "\n",
      "    accuracy                           0.74    384866\n",
      "   macro avg       0.56      0.73      0.53    384866\n",
      "weighted avg       0.93      0.74      0.81    384866\n",
      "\n",
      "[[270429  94290]\n",
      " [  5713  14434]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('XGB Test Accuracy:', accuracy_score(y_test, XGB_model_predict), '\\n')\n",
    "print(classification_report(y_test, XGB_model_predict))\n",
    "print(confusion_matrix(y_test, XGB_model_predict), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since XGBoost is performing well, we tried to run another gradient boosting method, called CatBoost, whose performance is often compared with Light GBM and XGBoost. It can in some cases, performs just as well as XGBoost, at a much faster rate (as expected from the cat family). To XGBoost's credit, it is older as was developed in 2014 compared to CatBoost in 2017.\n",
    "\n",
    "To implement CatBoost, we will tune its *iterations* parameter, which is the maximum number of trees. We will also specify the class_weights or ratio between the 2 classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = test.drop(\"Buy\", axis=1)\n",
    "y = test[\"Buy\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttotal: 214ms\tremaining: 31.9s\n",
      "1:\ttotal: 357ms\tremaining: 26.4s\n",
      "2:\ttotal: 539ms\tremaining: 26.4s\n",
      "3:\ttotal: 689ms\tremaining: 25.1s\n",
      "4:\ttotal: 870ms\tremaining: 25.2s\n",
      "5:\ttotal: 1.02s\tremaining: 24.6s\n",
      "6:\ttotal: 1.21s\tremaining: 24.8s\n",
      "7:\ttotal: 1.37s\tremaining: 24.4s\n",
      "8:\ttotal: 1.55s\tremaining: 24.3s\n",
      "9:\ttotal: 1.71s\tremaining: 24s\n",
      "10:\ttotal: 1.9s\tremaining: 24s\n",
      "11:\ttotal: 2.06s\tremaining: 23.7s\n",
      "12:\ttotal: 2.24s\tremaining: 23.6s\n",
      "13:\ttotal: 2.38s\tremaining: 23.1s\n",
      "14:\ttotal: 2.55s\tremaining: 23s\n",
      "15:\ttotal: 2.71s\tremaining: 22.7s\n",
      "16:\ttotal: 2.89s\tremaining: 22.6s\n",
      "17:\ttotal: 3.05s\tremaining: 22.4s\n",
      "18:\ttotal: 3.24s\tremaining: 22.3s\n",
      "19:\ttotal: 3.39s\tremaining: 22s\n",
      "20:\ttotal: 3.57s\tremaining: 21.9s\n",
      "21:\ttotal: 3.73s\tremaining: 21.7s\n",
      "22:\ttotal: 3.92s\tremaining: 21.6s\n",
      "23:\ttotal: 4.08s\tremaining: 21.4s\n",
      "24:\ttotal: 4.25s\tremaining: 21.3s\n",
      "25:\ttotal: 4.4s\tremaining: 21s\n",
      "26:\ttotal: 4.58s\tremaining: 20.9s\n",
      "27:\ttotal: 4.75s\tremaining: 20.7s\n",
      "28:\ttotal: 4.91s\tremaining: 20.5s\n",
      "29:\ttotal: 5.07s\tremaining: 20.3s\n",
      "30:\ttotal: 5.26s\tremaining: 20.2s\n",
      "31:\ttotal: 5.41s\tremaining: 20s\n",
      "32:\ttotal: 5.57s\tremaining: 19.7s\n",
      "33:\ttotal: 5.76s\tremaining: 19.6s\n",
      "34:\ttotal: 5.94s\tremaining: 19.5s\n",
      "35:\ttotal: 6.09s\tremaining: 19.3s\n",
      "36:\ttotal: 6.26s\tremaining: 19.1s\n",
      "37:\ttotal: 6.42s\tremaining: 18.9s\n",
      "38:\ttotal: 6.6s\tremaining: 18.8s\n",
      "39:\ttotal: 6.77s\tremaining: 18.6s\n",
      "40:\ttotal: 6.98s\tremaining: 18.5s\n",
      "41:\ttotal: 7.13s\tremaining: 18.3s\n",
      "42:\ttotal: 7.29s\tremaining: 18.1s\n",
      "43:\ttotal: 7.45s\tremaining: 17.9s\n",
      "44:\ttotal: 7.62s\tremaining: 17.8s\n",
      "45:\ttotal: 7.78s\tremaining: 17.6s\n",
      "46:\ttotal: 7.96s\tremaining: 17.4s\n",
      "47:\ttotal: 8.11s\tremaining: 17.2s\n",
      "48:\ttotal: 8.29s\tremaining: 17.1s\n",
      "49:\ttotal: 8.45s\tremaining: 16.9s\n",
      "50:\ttotal: 8.63s\tremaining: 16.7s\n",
      "51:\ttotal: 8.8s\tremaining: 16.6s\n",
      "52:\ttotal: 8.97s\tremaining: 16.4s\n",
      "53:\ttotal: 9.13s\tremaining: 16.2s\n",
      "54:\ttotal: 9.3s\tremaining: 16.1s\n",
      "55:\ttotal: 9.45s\tremaining: 15.9s\n",
      "56:\ttotal: 9.65s\tremaining: 15.7s\n",
      "57:\ttotal: 9.81s\tremaining: 15.6s\n",
      "58:\ttotal: 9.99s\tremaining: 15.4s\n",
      "59:\ttotal: 10.1s\tremaining: 15.2s\n",
      "60:\ttotal: 10.3s\tremaining: 15s\n",
      "61:\ttotal: 10.4s\tremaining: 14.8s\n",
      "62:\ttotal: 10.6s\tremaining: 14.6s\n",
      "63:\ttotal: 10.8s\tremaining: 14.5s\n",
      "64:\ttotal: 10.9s\tremaining: 14.3s\n",
      "65:\ttotal: 11.1s\tremaining: 14.1s\n",
      "66:\ttotal: 11.3s\tremaining: 13.9s\n",
      "67:\ttotal: 11.4s\tremaining: 13.8s\n",
      "68:\ttotal: 11.6s\tremaining: 13.7s\n",
      "69:\ttotal: 11.8s\tremaining: 13.5s\n",
      "70:\ttotal: 12s\tremaining: 13.3s\n",
      "71:\ttotal: 12.1s\tremaining: 13.1s\n",
      "72:\ttotal: 12.3s\tremaining: 13s\n",
      "73:\ttotal: 12.5s\tremaining: 12.8s\n",
      "74:\ttotal: 12.6s\tremaining: 12.6s\n",
      "75:\ttotal: 12.8s\tremaining: 12.5s\n",
      "76:\ttotal: 13s\tremaining: 12.3s\n",
      "77:\ttotal: 13.2s\tremaining: 12.1s\n",
      "78:\ttotal: 13.3s\tremaining: 12s\n",
      "79:\ttotal: 13.5s\tremaining: 11.8s\n",
      "80:\ttotal: 13.7s\tremaining: 11.7s\n",
      "81:\ttotal: 13.8s\tremaining: 11.5s\n",
      "82:\ttotal: 14s\tremaining: 11.3s\n",
      "83:\ttotal: 14.2s\tremaining: 11.2s\n",
      "84:\ttotal: 14.4s\tremaining: 11s\n",
      "85:\ttotal: 14.6s\tremaining: 10.8s\n",
      "86:\ttotal: 14.7s\tremaining: 10.7s\n",
      "87:\ttotal: 14.9s\tremaining: 10.5s\n",
      "88:\ttotal: 15s\tremaining: 10.3s\n",
      "89:\ttotal: 15.2s\tremaining: 10.1s\n",
      "90:\ttotal: 15.4s\tremaining: 9.96s\n",
      "91:\ttotal: 15.5s\tremaining: 9.79s\n",
      "92:\ttotal: 15.7s\tremaining: 9.64s\n",
      "93:\ttotal: 15.9s\tremaining: 9.46s\n",
      "94:\ttotal: 16s\tremaining: 9.29s\n",
      "95:\ttotal: 16.2s\tremaining: 9.12s\n",
      "96:\ttotal: 16.4s\tremaining: 8.95s\n",
      "97:\ttotal: 16.5s\tremaining: 8.77s\n",
      "98:\ttotal: 16.7s\tremaining: 8.62s\n",
      "99:\ttotal: 16.9s\tremaining: 8.44s\n",
      "100:\ttotal: 17.1s\tremaining: 8.27s\n",
      "101:\ttotal: 17.2s\tremaining: 8.11s\n",
      "102:\ttotal: 17.5s\tremaining: 7.97s\n",
      "103:\ttotal: 17.6s\tremaining: 7.8s\n",
      "104:\ttotal: 17.8s\tremaining: 7.63s\n",
      "105:\ttotal: 18s\tremaining: 7.46s\n",
      "106:\ttotal: 18.2s\tremaining: 7.31s\n",
      "107:\ttotal: 18.4s\tremaining: 7.14s\n",
      "108:\ttotal: 18.5s\tremaining: 6.97s\n",
      "109:\ttotal: 18.7s\tremaining: 6.8s\n",
      "110:\ttotal: 18.9s\tremaining: 6.63s\n",
      "111:\ttotal: 19s\tremaining: 6.46s\n",
      "112:\ttotal: 19.2s\tremaining: 6.28s\n",
      "113:\ttotal: 19.4s\tremaining: 6.12s\n",
      "114:\ttotal: 19.6s\tremaining: 5.97s\n",
      "115:\ttotal: 19.8s\tremaining: 5.8s\n",
      "116:\ttotal: 19.9s\tremaining: 5.63s\n",
      "117:\ttotal: 20.1s\tremaining: 5.45s\n",
      "118:\ttotal: 20.3s\tremaining: 5.28s\n",
      "119:\ttotal: 20.4s\tremaining: 5.1s\n",
      "120:\ttotal: 20.6s\tremaining: 4.93s\n",
      "121:\ttotal: 20.7s\tremaining: 4.76s\n",
      "122:\ttotal: 20.9s\tremaining: 4.59s\n",
      "123:\ttotal: 21.1s\tremaining: 4.42s\n",
      "124:\ttotal: 21.2s\tremaining: 4.25s\n",
      "125:\ttotal: 21.4s\tremaining: 4.07s\n",
      "126:\ttotal: 21.6s\tremaining: 3.9s\n",
      "127:\ttotal: 21.7s\tremaining: 3.73s\n",
      "128:\ttotal: 21.9s\tremaining: 3.56s\n",
      "129:\ttotal: 22.1s\tremaining: 3.39s\n",
      "130:\ttotal: 22.2s\tremaining: 3.22s\n",
      "131:\ttotal: 22.4s\tremaining: 3.05s\n",
      "132:\ttotal: 22.5s\tremaining: 2.88s\n",
      "133:\ttotal: 22.7s\tremaining: 2.71s\n",
      "134:\ttotal: 22.9s\tremaining: 2.54s\n",
      "135:\ttotal: 23s\tremaining: 2.37s\n",
      "136:\ttotal: 23.2s\tremaining: 2.2s\n",
      "137:\ttotal: 23.3s\tremaining: 2.03s\n",
      "138:\ttotal: 23.5s\tremaining: 1.86s\n",
      "139:\ttotal: 23.7s\tremaining: 1.69s\n",
      "140:\ttotal: 23.8s\tremaining: 1.52s\n",
      "141:\ttotal: 23.9s\tremaining: 1.35s\n",
      "142:\ttotal: 24.1s\tremaining: 1.18s\n",
      "143:\ttotal: 24.3s\tremaining: 1.01s\n",
      "144:\ttotal: 24.4s\tremaining: 842ms\n",
      "145:\ttotal: 24.6s\tremaining: 673ms\n",
      "146:\ttotal: 24.8s\tremaining: 505ms\n",
      "147:\ttotal: 24.9s\tremaining: 337ms\n",
      "148:\ttotal: 25.1s\tremaining: 168ms\n",
      "149:\ttotal: 25.3s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "params = {'iterations': range(50, 500, 50)}\n",
    "\n",
    "model = CatBoostClassifier(eval_metric='AUC', learning_rate = 0.2, class_weights=[1, 18])\n",
    "ctb = GridSearchCV(model, param_grid=params, cv=5, n_jobs=-1, scoring ='roc_auc', refit =True)\n",
    "ctb.fit(X_train, y_train)\n",
    "y_pred = ctb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nan_mode': 'Min', 'eval_metric': 'AUC', 'iterations': 150, 'sampling_frequency': 'PerTree', 'leaf_estimation_method': 'Newton', 'grow_policy': 'SymmetricTree', 'penalties_coefficient': 1, 'boosting_type': 'Plain', 'model_shrink_mode': 'Constant', 'feature_border_type': 'GreedyLogSum', 'bayesian_matrix_reg': 0.10000000149011612, 'l2_leaf_reg': 3, 'random_strength': 1, 'rsm': 1, 'boost_from_average': False, 'model_size_reg': 0.5, 'pool_metainfo_options': {'tags': {}}, 'subsample': 0.800000011920929, 'use_best_model': False, 'class_names': [0, 1], 'random_seed': 0, 'depth': 6, 'posterior_sampling': False, 'border_count': 254, 'class_weights': [1, 18], 'classes_count': 0, 'auto_class_weights': 'None', 'sparse_features_conflict_fraction': 0, 'leaf_estimation_backtracking': 'AnyImprovement', 'best_model_min_trees': 1, 'model_shrink_rate': 0, 'min_data_in_leaf': 1, 'loss_function': 'Logloss', 'learning_rate': 0.20000000298023224, 'score_function': 'Cosine', 'task_type': 'CPU', 'leaf_estimation_iterations': 1, 'bootstrap_type': 'MVS', 'max_leaves': 64}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.74      0.84    364719\n",
      "           1       0.13      0.72      0.22     20147\n",
      "\n",
      "    accuracy                           0.74    384866\n",
      "   macro avg       0.56      0.73      0.53    384866\n",
      "weighted avg       0.94      0.74      0.81    384866\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(ctb.best_estimator_.get_all_params())\n",
    "print(classification_report(y_test, y_pred), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(269873, 94846, 5637, 14510)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Light GBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply the Light GBM method to compare its performance to XGBoost and CatBoost. It differs from XGBoost in which it construct trees using Gradient-Based One-Sided Sampling, which is a novel approach to sampling method and as it brings down the complexity in training the decision trees, it subsequently makes the algorithm much faster to run. \n",
    "\n",
    "To implement LightGBM, we will tune 2 of its parameters:\n",
    "1. *n_estimators*: number of boosted trees to fit\n",
    "2. *boosting_type*: boosting types\n",
    "    * 'gbdt': gradient boosting decision tree   \n",
    "    * 'dart': dropouts meet multiple additive regression trees    \n",
    "    * 'goss': gradient-based one-side sampling  \n",
    "    * 'rf': random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = test.drop(\"Buy\", axis=1)\n",
    "y = test[\"Buy\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lilya\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.79979637 0.79960632 0.79885568 0.79775741 0.79672563 0.79559372\n",
      " 0.79429898 0.7931219  0.79194581 0.79975816 0.80093253 0.8011798\n",
      " 0.80152488 0.80147421 0.80136437 0.80120152 0.80103931 0.80073234\n",
      " 0.79980574 0.79936134 0.79836386 0.7969707  0.79558737 0.79406084\n",
      " 0.79255793 0.79120326 0.78968477        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': range(50, 500, 50),\n",
    "         'boosting_type': ['gbdt', 'dart', 'goss', 'rf']}\n",
    "\n",
    "model = LGBMClassifier(objective='binary', learning_rate = 0.2, scale_pos_weight=18)\n",
    "lgbm = GridSearchCV(model, param_grid=params, cv=5, n_jobs=-1, scoring ='roc_auc', refit =True)\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_pred = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(boosting_type='dart', learning_rate=0.2, n_estimators=200,\n",
      "               objective='binary', scale_pos_weight=18)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.74      0.84    364719\n",
      "           1       0.13      0.72      0.22     20147\n",
      "\n",
      "    accuracy                           0.74    384866\n",
      "   macro avg       0.56      0.73      0.53    384866\n",
      "weighted avg       0.94      0.74      0.81    384866\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(lgbm.best_estimator_)\n",
    "print(classification_report(y_test, y_pred), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(269802, 94917, 5653, 14494)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we tried Neural Networks method, which is superior at capturing complex relationships between varibles by searching through different models in its black box to find patterns. In its black box, there can be one or more linear or non-linear hidden layers. \n",
    "\n",
    "We will apply SMOTE to the data as there is no parameter to adjust for the imbalanced in data in *MLPClassifier*. Additionally, we need to normalise the data before running neural networks as it is sensitive to feature scaling. We also specify that it will train using 2 hidden layers as 1 or 2 should give a decent performance for most problems, and 14 as number of neurons as we have 14 features in our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = test.drop(\"Buy\", axis=1)\n",
    "y = test[\"Buy\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lilya\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=0.1, hidden_layer_sizes=(14, 14),\n",
       "              max_iter=100)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os = SMOTE(random_state = 42, n_jobs=-1)\n",
    "columns = X_train.columns\n",
    "\n",
    "os_data_X, os_data_y = os.fit_resample(X_train, y_train)\n",
    "os_data_X = pd.DataFrame(data = os_data_X,columns = columns)\n",
    "os_data_y = pd.DataFrame(data = os_data_y,columns = ['Buy'])\n",
    "scaler = StandardScaler()\n",
    "NN_Xtrain = scaler.fit_transform(os_data_X)\n",
    "NN_Xtest = scaler.transform(X_test)\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes = (14, 14), max_iter = 100, solver='adam', alpha=0.1, activation='logistic') \n",
    "#2 hidden layers and 'adam' optimizer works well for large dataset\n",
    "mlp.fit(NN_Xtrain, os_data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.89      0.93    364719\n",
      "           1       0.17      0.39      0.23     20147\n",
      "\n",
      "    accuracy                           0.87    384866\n",
      "   macro avg       0.57      0.64      0.58    384866\n",
      "weighted avg       0.92      0.87      0.89    384866\n",
      "\n",
      "(325689, 39030, 12338, 7809) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds = mlp.predict(NN_Xtest)\n",
    "print(classification_report(y_test, y_preds))\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_preds).ravel()\n",
    "print((tn, fp, fn, tp), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we tried a non-probabilistic classifier called Support Vector Machine (SVM). This method is effective in high dimensional space and can control overfitting using its regularisation term. Additionally, it can use different kernel tricks, like polynomial or radial basis function, to transform non-linear problems to linearly separable cases. \n",
    "\n",
    "*SVC()* from sklearn.svm package only works well for dataset with tens of thousands observations. Since our sample has over 100,000 observations, we will need to use *SGDClassifier()* or *LinearSVC()* instead to implement SVM. Here, we will use *SGDClassifier()* as it is more flexible and faster in some cases than *LinearSVC()*. \n",
    "\n",
    "We will explore different kernel approximations: linear and polynomial as they seem to work well from the results below, thus it's highly unlikely that radial basis function will be a good fit. Since it will take a longer time to tune the parameters using *GridSearchCV*, we will specify the parameters directly as below:\n",
    "1. *max_iter*: the default maximum number of passes over training data is 1000. However, in the interest of time and computer limitations, we will use 100 \n",
    "2. *loss*: we used hinge as it is a loss function typically used for training classifiers\n",
    "3. *penalty*: we used l1 as our regularisation term as it might bring sparsity in our model by shrinking some feature coefficients to 0, which helps reducing its complexity while still reducing the model's variance\n",
    "4. *class_weight*: even though our actual ratio is 1:18, after testing with a few weights, we found that 1:22 gives us better performance results, which is slightly higher than the original ratio\n",
    "5. *alpha*: given that the default is 0.0001 and the higher the value, the stronger the regularisation, we chose alpha value at 0.01 so that it will penalises more when there is a misclassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = test.drop(\"Buy\", axis=1)\n",
    "y = test[\"Buy\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.76      0.85    364719\n",
      "           1       0.13      0.64      0.21     20147\n",
      "\n",
      "    accuracy                           0.75    384866\n",
      "   macro avg       0.55      0.70      0.53    384866\n",
      "weighted avg       0.93      0.75      0.82    384866\n",
      "\n",
      "(276956, 87763, 7206, 12941) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "SVM_Xtrain = scaler.fit_transform(X_train)\n",
    "SVM_Xtest = scaler.transform(X_test)\n",
    "\n",
    "svm = SGDClassifier(max_iter=100, loss='hinge', n_jobs=-1, penalty='l1', alpha = 0.01, class_weight={0: 1, 1: 22})\n",
    "#adjusting class weight to get better balance between recall rates for class 0 and class 1 \n",
    "svm.fit(SVM_Xtrain, y_train)\n",
    "y_preds = svm.predict(SVM_Xtest)\n",
    "print(classification_report(y_test, y_preds))\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_preds).ravel()\n",
    "print((tn, fp, fn, tp), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will transform the data to 2nd degree polynomial kernel before running *SGDClassifier* as 3rd degree polynomial did not fit well with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_feature = PolynomialCountSketch(degree = 2, n_components = 140) #optimal n_components = 10*n_features\n",
    "SVM_Xtrain = poly_feature.fit_transform(X_train)\n",
    "SVM_Xtest = poly_feature.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.64      0.77    364719\n",
      "           1       0.08      0.54      0.14     20147\n",
      "\n",
      "    accuracy                           0.64    384866\n",
      "   macro avg       0.52      0.59      0.45    384866\n",
      "weighted avg       0.92      0.64      0.74    384866\n",
      "\n",
      "(234401, 130318, 9187, 10960) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm = SGDClassifier(max_iter=100, loss='hinge', n_jobs=-1, penalty='l1', alpha = 0.01, class_weight={0: 1, 1: 20})\n",
    "#adjust alpha to vary recall rates \n",
    "svm.fit(SVM_Xtrain, y_train)\n",
    "y_preds = svm.predict(SVM_Xtest)\n",
    "print(classification_report(y_test, y_preds))\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_preds).ravel()\n",
    "print((tn, fp, fn, tp), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Stacking Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stacking is an ensemble method that combines multiple base classification models predictions, then it uses a blending model to combine the prediction of the base models. Stacking can harness the capabilities of different models and improve performance than any single model in the ensemble. The base models can be complex and diverse, while the blending model is often simple as it only needs to provide a smooth interpretation of the predictions output by the base models. \n",
    "\n",
    "Here, we tried a combinations of models to see if we can improve their performances. SVM, CatBoost and Logistic Regression have highest performance from the results earlier. CatBoost was chosen over Light GBM and XGBoost even though they all have the same performance because CatBoost takes the shortest time to train. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = test.drop(\"Buy\", axis=1)\n",
    "y = test[\"Buy\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97    364719\n",
      "           1       0.25      0.00      0.00     20147\n",
      "\n",
      "    accuracy                           0.95    384866\n",
      "   macro avg       0.60      0.50      0.49    384866\n",
      "weighted avg       0.91      0.95      0.92    384866\n",
      "\n"
     ]
    }
   ],
   "source": [
    "estimators = [('svm', make_pipeline(StandardScaler(), \n",
    "                                    SGDClassifier(max_iter=100, loss='hinge', n_jobs=-1, \n",
    "                                                  penalty='l1', alpha = 0.01, class_weight={0: 1, 1: 22}))),\n",
    "              ('ctb', CatBoostClassifier(eval_metric='AUC', learning_rate = 0.2, class_weights=[1, 18], iterations=150)),\n",
    "             ('lg', make_pipeline(StandardScaler(), LogisticRegression(C=1000, solver='saga', class_weight={0: 1, 1:22})))]\n",
    "clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(), cv=5, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As observed above, Logistic Regression, XGBoost, CatBoost, Light GBM, and SVM did well in our sample dataset. Even though Logistic Regression did not do as well as the others mentioned, we will still implement it on our full dataset as it is easy to implement while giving considerably good results. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
